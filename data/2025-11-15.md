<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: 本文提出了一种机器人无关的奖励函数，通过强化学习实现双足机器人的受控软着陆，平衡期望最终姿态与冲击最小化，并保护关键机器人部件。


<details>
  <summary>Details</summary>
Motivation: 尽管双足机器人在鲁棒运动方面取得进展，但在现实世界中仍有跌倒风险。大多数研究关注防止跌倒，而本文专注于跌倒现象本身，旨在减少机器人物理损伤并让用户控制机器人的最终姿态。

Method: 提出机器人无关的奖励函数，在强化学习中平衡期望最终姿态达成与冲击最小化；引入基于仿真的初始和最终姿态采样策略，使策略对广泛的初始跌倒条件具有鲁棒性，并能在推理时指定任意未见过的最终姿态。

Result: 通过仿真和真实世界实验证明，即使是双足机器人也能执行受控的软着陆。

Conclusion: 本文展示了双足机器人能够实现受控软着陆，为机器人安全操作提供了新的解决方案。

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>
