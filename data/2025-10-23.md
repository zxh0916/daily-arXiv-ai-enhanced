<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions](https://arxiv.org/abs/2510.18986)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的地形映射框架，通过内部传感在运动过程中估计高程、足部滑移、能量成本和稳定性裕度，并在模拟月球环境中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 月球极区永久阴影区域地形复杂，适合腿式机器人探索，但现有外部传感器无法量化地形与机器人的物理交互。

Method: 使用四足机器人内部传感数据，增量式构建反映地形交互的多层2.5D网格地图，包含高程、滑移、能耗和稳定性指标。

Result: 在模拟月球环境中使用21公斤四足机器人Aliengo进行测试，在月球重力和地形条件下表现出稳定的映射性能。

Conclusion: 该框架能够有效量化地形与机器人的物理交互，为月球探索任务提供了实用的地形感知能力。

Abstract: Permanently Shadowed Regions (PSRs) near the lunar poles are of interest for
future exploration due to their potential to contain water ice and preserve
geological records. Their complex, uneven terrain favors the use of legged
robots, which can traverse challenging surfaces while collecting in-situ data,
and have proven effective in Earth analogs, including dark caves, when equipped
with onboard lighting. While exteroceptive sensors like cameras and lidars can
capture terrain geometry and even semantic information, they cannot quantify
its physical interaction with the robot, a capability provided by
proprioceptive sensing. We propose a terrain mapping framework for quadruped
robots, which estimates elevation, foot slippage, energy cost, and stability
margins from internal sensing during locomotion. These metrics are
incrementally integrated into a multi-layer 2.5D gridmap that reflects terrain
interaction from the robot's perspective. The system is evaluated in a
simulator that mimics a lunar environment, using the 21 kg quadruped robot
Aliengo, showing consistent mapping performance under lunar gravity and terrain
conditions.

</details>


### [2] [Underwater Dense Mapping with the First Compact 3D Sonar](https://arxiv.org/abs/2510.18991)
*Chinmay Burgul,Yewei Huang,Michalis Chatzispyrou,Ioannis Rekleitis,Alberto Quattrini Li,Marios Xanthidis*

Main category: cs.RO

TL;DR: 本文首次研究了紧凑型3D声纳的性能、能力和应用机会，提出了3D声纳与相机的标定方法，开发了新颖的水下建图和SLAM流程，并在水下洞穴等挑战性环境中进行了测试验证。


<details>
  <summary>Details</summary>
Motivation: 传统水下状态估计主要依赖2D声学传感器，信息有限且存在空间模糊性。随着首个紧凑型3D声纳的出现，需要评估其在复杂水下环境中的性能和应用潜力。

Method: 提出了3D声纳与相机的外部参数标定程序；研究了不同表面和材料的声学响应特性；开发了新颖的水下建图和SLAM流程；在几何和声学挑战性水下环境中进行部署测试。

Result: 3D声纳能够捕获一致的空间信息，实现数百米范围内详细的重建和定位；同时揭示了声波传播相关的挑战；收集的数据集将公开发布。

Conclusion: 3D声纳为水下状态估计提供了新的可能性，能够在水下洞穴等复杂环境中实现可靠的空间感知，但仍面临声学传播相关的技术挑战。

Abstract: In the past decade, the adoption of compact 3D range sensors, such as LiDARs,
has driven the developments of robust state-estimation pipelines, making them a
standard sensor for aerial, ground, and space autonomy. Unfortunately, poor
propagation of electromagnetic waves underwater, has limited the
visibility-independent sensing options of underwater state-estimation to
acoustic range sensors, which provide 2D information including, at-best,
spatially ambiguous information. This paper, to the best of our knowledge, is
the first study examining the performance, capacity, and opportunities arising
from the recent introduction of the first compact 3D sonar. Towards that
purpose, we introduce calibration procedures for extracting the extrinsics
between the 3D sonar and a camera and we provide a study on acoustic response
in different surfaces and materials. Moreover, we provide novel mapping and
SLAM pipelines tested in deployments in underwater cave systems and other
geometrically and acoustically challenging underwater environments. Our
assessment showcases the unique capacity of 3D sonars to capture consistent
spatial information allowing for detailed reconstructions and localization in
datasets expanding to hundreds of meters. At the same time it highlights
remaining challenges related to acoustic propagation, as found also in other
acoustic sensors. Datasets collected for our evaluations would be released and
shared with the community to enable further research advancements.

</details>


### [3] [SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar](https://arxiv.org/abs/2510.18996)
*Susheel Vadakkekuruppath,Herman B. Amundsen,Jason M. O'Kane,Marios Xanthidis*

Main category: cs.RO

TL;DR: SHRUMS是首个集成3D声纳的水下自主导航系统，通过虚拟传感器测量技术，在能见度极差的水下复杂3D环境中实现鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 水下3D自主导航面临传感器限制，传统LiDAR在水下效果不佳，而新型3D声纳传感器刚刚可用，需要开发相应的导航系统。

Method: 提出传感器虚拟化概念，从不存在但参数可定制的传感器中虚拟生成测量数据，以适应新型传感器数据流并实现实时局部最优性能。

Result: 使用真实3D声纳传感器数据验证了系统在挑战性环境中的有效性，实时构建局部地图，系统表现出强鲁棒性。

Conclusion: SHRUMS成功解决了水下3D导航问题，为水下自主系统提供了可行的解决方案，完整的现场部署验证即将进行。

Abstract: Autonomous navigation in 3D is a fundamental problem for autonomy. Despite
major advancements in terrestrial and aerial settings due to improved range
sensors including LiDAR, compact sensors with similar capabilities for
underwater robots have only recently become available, in the form of 3D
sonars. This paper introduces a novel underwater 3D navigation pipeline, called
SHRUMS (Sensor Hallucination for Robust Underwater Motion planning with 3D
Sonar). To the best of the authors' knowledge, SHRUMS is the first underwater
autonomous navigation stack to integrate a 3D sonar. The proposed pipeline
exhibits strong robustness while operating in complex 3D environments in spite
of extremely poor visibility conditions. To accommodate the intricacies of the
novel sensor data stream while achieving real-time locally optimal performance,
SHRUMS introduces the concept of hallucinating sensor measurements from
non-existent sensors with convenient arbitrary parameters, tailored to
application specific requirements. The proposed concepts are validated with
real 3D sonar sensor data, utilizing real inputs in challenging settings and
local maps constructed in real-time. Field deployments validating the proposed
approach in full are planned in the very near future.

</details>


### [4] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文针对具有独立转向的过驱动四轮驱动系统（4WIS）的运动规划与控制问题，其中机械约束限制了车轮无法实现360度全向旋转。通过数学建模转向约束，设计考虑转向约束和速度过渡平滑性的运动规划器，并开发能够正确处理不连续性穿越的运动控制器。


<details>
  <summary>Details</summary>
Motivation: 解决四轮独立转向系统中由于机械约束导致车轮无法360度旋转而产生的配置空间约束和不连续性问题，这些不连续性会影响机器人运动的平滑性。

Method: 引入转向约束的数学公式化，推导划分速度空间的不连续性平面，设计考虑转向约束和速度过渡平滑性的路径跟踪和避障运动规划器，使用局部反馈生成驱动并正确处理不连续性穿越的运动控制器。

Result: 将提出的运动规划器实现为ROS导航包的扩展，并在仿真和物理机器人上进行了系统评估。

Conclusion: 提出的方法能够有效处理四轮独立转向系统中的转向约束和不连续性问题，实现平滑高效的运动控制。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [5] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 提出一种用于短期交会事件的低推力碰撞规避机动规划算法，将非凸优化问题转化为凸半定规划，实现全局最优解，确保在最近接近点达到期望的碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星密度增加，传统手动碰撞规避规划过程耗时且效率低，需要自动化解决方案来提高评估和缓解碰撞的效率。

Method: 首先将问题表述为非凸二次约束二次规划(QCQP)，然后使用Shor松弛将其转化为凸半定规划(SDP)，经验证明该松弛是紧的，可以恢复原始问题的全局最优解。

Result: 算法能够生成最小能量解，确保在最近接近点达到期望的碰撞概率，如果无法满足约束则转化为最小风险解，通过高保真仿真验证了其有效性。

Conclusion: 该方法为航天器碰撞规避提供了一种有效的自动化解决方案，能够显著降低碰撞风险，适应日益拥挤的低地球轨道环境。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>


### [6] [Sample-Based Hybrid Mode Control: Asymptotically Optimal Switching of Algorithmic and Non-Differentiable Control Modes](https://arxiv.org/abs/2510.19074)
*Yilang Liu,Haoxiang You,Ian Abraham*

Main category: cs.RO

TL;DR: 本文提出了一种基于采样的混合模式控制解决方案，通过将混合控制模式建模为整数优化问题，有效选择控制模式、切换时机和持续时间。


<details>
  <summary>Details</summary>
Motivation: 解决非可微和算法混合模式中的混合控制问题，需要在长期规划和高频控制之间进行反应性切换。

Method: 将混合控制模式建模为整数优化问题，采用基于采样的变体在整数域中高效搜索最优解。

Result: 该方法在多个机器人相关任务中表现出强大的性能保证，能够合成复杂算法和策略来实现复合行为和挑战性任务。

Conclusion: 所提出的方法在需要长期规划和高频控制之间反应性切换的实际机器人应用中表现出有效性。

Abstract: This paper investigates a sample-based solution to the hybrid mode control
problem across non-differentiable and algorithmic hybrid modes. Our approach
reasons about a set of hybrid control modes as an integer-based optimization
problem where we select what mode to apply, when to switch to another mode, and
the duration for which we are in a given control mode. A sample-based variation
is derived to efficiently search the integer domain for optimal solutions. We
find our formulation yields strong performance guarantees that can be applied
to a number of robotics-related tasks. In addition, our approach is able to
synthesize complex algorithms and policies to compound behaviors and achieve
challenging tasks. Last, we demonstrate the effectiveness of our approach in
real-world robotic examples that require reactive switching between long-term
planning and high-frequency control.

</details>


### [7] [Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory](https://arxiv.org/abs/2510.19081)
*Shifa Sulaiman,Tobias Busk Jensen,Stefan Hein Bengtson,Simon Bøgh*

Main category: cs.RO

TL;DR: 开发用于自主实验室环境的移动机械臂，通过DH建模和逆运动学实现精确操作，结合视觉算法进行实时物体检测和姿态估计，增强纹理物体的抓取能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自主系统的发展，实验室中机器人的应用范围扩大，需要开发能够协助人类操作员的移动机械臂，以支持自主实验和人类-机器人协作。

Method: 基于Denavit Hartenberg约定进行机械臂运动学建模，确定逆运动学解；实现结合特征检测和单应性驱动的姿态估计的视觉方法，利用深度信息在3D空间中表示物体姿态。

Result: 系统能够适应物体方向变化，在多样化环境中实现稳健的自主操作，支持动态抓取和跟随任务。

Conclusion: 这项工作通过实现自主实验和人类-机器人协作，为下一代化学实验室的可扩展性和可重复性做出了贡献。

Abstract: Recent advances in robotics and autonomous systems have broadened the use of
robots in laboratory settings, including automated synthesis, scalable reaction
workflows, and collaborative tasks in self-driving laboratories (SDLs). This
paper presents a comprehensive development of a mobile manipulator designed to
assist human operators in such autonomous lab environments. Kinematic modeling
of the manipulator is carried out based on the Denavit Hartenberg (DH)
convention and inverse kinematics solution is determined to enable precise and
adaptive manipulation capabilities. A key focus of this research is enhancing
the manipulator ability to reliably grasp textured objects as a critical
component of autonomous handling tasks. Advanced vision-based algorithms are
implemented to perform real-time object detection and pose estimation, guiding
the manipulator in dynamic grasping and following tasks. In this work, we
integrate a vision method that combines feature-based detection with
homography-driven pose estimation, leveraging depth information to represent an
object pose as a $2$D planar projection within $3$D space. This adaptive
capability enables the system to accommodate variations in object orientation
and supports robust autonomous manipulation across diverse environments. By
enabling autonomous experimentation and human-robot collaboration, this work
contributes to the scalability and reproducibility of next-generation chemical
laboratories

</details>


### [8] [Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements](https://arxiv.org/abs/2510.19101)
*Matthew Jiang,Shipeng Liu,Feifei Qian*

Main category: cs.RO

TL;DR: SAEGT是一个用于腿式机器人在未知颗粒地形中安全探索的导航框架，仅使用本体感知来评估地形可通行性


<details>
  <summary>Details</summary>
Motivation: 腿式机器人虽然能通过力交互感知地形，但在高度可变形或不稳定地形中仍面临挑战，需要一种仅依赖本体感知的安全探索方法

Method: 使用高斯过程回归从腿-地形交互中在线估计安全区域和边界区域，结合反应式控制器实现实时安全探索和导航

Result: 在仿真中证明了SAEGT能够仅使用本体感知估计的可通行性安全探索并导航到指定目标

Conclusion: SAEGT框架为腿式机器人在视觉输入无法捕捉地形可变形性的情况下提供了可靠的安全探索能力

Abstract: Legged robots can sense terrain through force interactions during locomotion,
offering more reliable traversability estimates than remote sensing and serving
as scouts for guiding wheeled rovers in challenging environments. However, even
legged scouts face challenges when traversing highly deformable or unstable
terrain. We present Safe Active Exploration for Granular Terrain (SAEGT), a
navigation framework that enables legged robots to safely explore unknown
granular environments using proprioceptive sensing, particularly where visual
input fails to capture terrain deformability. SAEGT estimates the safe region
and frontier region online from leg-terrain interactions using Gaussian Process
regression for traversability assessment, with a reactive controller for
real-time safe exploration and navigation. SAEGT demonstrated its ability to
safely explore and navigate toward a specified goal using only proprioceptively
estimated traversability in simulation.

</details>


### [9] [A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model](https://arxiv.org/abs/2510.19128)
*Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran*

Main category: cs.RO

TL;DR: 提出GADGET框架，使用扩散模型生成机器人关节空间轨迹，结合场景表示和起始目标配置，实现零样本迁移到新环境和机器人硬件。


<details>
  <summary>Details</summary>
Motivation: 解决高维复杂环境中机器人路径规划的计算效率低、参数调优困难以及现有学习方法泛化能力不足的问题。

Method: 采用混合双条件机制，结合无分类器引导的场景编码和基于控制屏障函数的安全整形，在去噪过程中集成环境感知和实时碰撞避免。

Result: 在球形障碍物、箱拣选和货架环境中实现高成功率、低碰撞强度，CBF引导进一步提升安全性，在多种机器人平台上展示良好迁移性。

Conclusion: GADGET框架能够生成安全、无碰撞的轨迹，支持零样本迁移到新环境和机器人硬件，在真实物理执行中验证了有效性。

Abstract: Path planning for a robotic system in high-dimensional cluttered environments
needs to be efficient, safe, and adaptable for different environments and
hardware. Conventional methods face high computation time and require extensive
parameter tuning, while prior learning-based methods still fail to generalize
effectively. The primary goal of this research is to develop a path planning
framework capable of generalizing to unseen environments and new robotic
manipulators without the need for retraining. We present GADGET (Generalizable
and Adaptive Diffusion-Guided Environment-aware Trajectory generation), a
diffusion-based planning model that generates joint-space trajectories
conditioned on voxelized scene representations as well as start and goal
configurations. A key innovation is GADGET's hybrid dual-conditioning mechanism
that combines classifier-free guidance via learned scene encoding with
classifier-guided Control Barrier Function (CBF) safety shaping, integrating
environment awareness with real-time collision avoidance directly in the
denoising process. This design supports zero-shot transfer to new environments
and robotic embodiments without retraining. Experimental results show that
GADGET achieves high success rates with low collision intensity in
spherical-obstacle, bin-picking, and shelf environments, with CBF guidance
further improving safety. Moreover, comparative evaluations indicate strong
performance relative to both sampling-based and learning-based baselines.
Furthermore, GADGET provides transferability across Franka Panda, Kinova Gen3
(6/7-DoF), and UR5 robots, and physical execution on a Kinova Gen3 demonstrates
its ability to generate safe, collision-free trajectories in real-world
settings.

</details>


### [10] [GRASPLAT: Enabling dexterous grasping through novel view synthesis](https://arxiv.org/abs/2510.19200)
*Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue*

Main category: cs.RO

TL;DR: GRASPLAT是一种新颖的抓取框架，仅使用RGB图像训练，通过3D高斯泼溅生成手-物体交互的高保真新视图，结合光度损失优化抓取预测，在合成和真实世界数据集上比现有图像方法提升抓取成功率高达36.9%。


<details>
  <summary>Details</summary>
Motivation: 多指机器人抓取仍然是一个重大挑战。现有方法依赖完整的3D扫描来预测抓取姿态，但在真实场景中获取高质量3D数据很困难。

Method: 利用3D高斯泼溅生成真实手-物体交互的高保真新视图，通过合成物理上合理的手抓取物体图像来回归对应的手关节，结合光度损失最小化渲染图像与真实图像之间的差异。

Result: 在合成和真实世界抓取数据集上的广泛实验表明，GRASPLAT比现有基于图像的方法提高抓取成功率高达36.9%。

Conclusion: GRASPLAT展示了仅使用RGB图像训练就能实现有效抓取预测的可行性，为机器人抓取提供了一种更实用的解决方案。

Abstract: Achieving dexterous robotic grasping with multi-fingered hands remains a
significant challenge. While existing methods rely on complete 3D scans to
predict grasp poses, these approaches face limitations due to the difficulty of
acquiring high-quality 3D data in real-world scenarios. In this paper, we
introduce GRASPLAT, a novel grasping framework that leverages consistent 3D
information while being trained solely on RGB images. Our key insight is that
by synthesizing physically plausible images of a hand grasping an object, we
can regress the corresponding hand joints for a successful grasp. To achieve
this, we utilize 3D Gaussian Splatting to generate high-fidelity novel views of
real hand-object interactions, enabling end-to-end training with RGB data.
Unlike prior methods, our approach incorporates a photometric loss that refines
grasp predictions by minimizing discrepancies between rendered and real images.
We conduct extensive experiments on both synthetic and real-world grasping
datasets, demonstrating that GRASPLAT improves grasp success rates up to 36.9%
over existing image-based methods. Project page:
https://mbortolon97.github.io/grasplat/

</details>


### [11] [Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models](https://arxiv.org/abs/2510.19268)
*Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi*

Main category: cs.RO

TL;DR: 提出了一种用于解决可变形线性物体（如电缆和绳索）长时程路由任务的自主分层框架，结合视觉语言模型进行高层推理和强化学习训练的低层技能执行，在长时程路由场景中达到92.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 工业装配线和日常生活中常见的可变形线性物体路由任务具有挑战性，需要长时程规划、可靠技能执行，并适应非线性动力学、分解抽象路由目标、生成多步骤计划，这些都需要准确的高层推理。

Method: 采用分层框架：利用视觉语言模型进行上下文高层推理合成可行计划，通过强化学习训练低层技能执行计划，并引入故障恢复机制将可变形线性物体重新定向到可插入状态以提高鲁棒性。

Result: 该方法在涉及物体属性、空间描述以及隐式语言命令的多样化场景中具有良好泛化能力，比次优基线方法性能提高近50%，在长时程路由场景中总体成功率达到92.5%。

Conclusion: 提出的分层框架能够有效解决具有挑战性的可变形线性物体路由任务，通过结合视觉语言模型的高层推理和强化学习的低层技能，实现了在复杂长时程场景中的高成功率执行。

Abstract: Long-horizon routing tasks of deformable linear objects (DLOs), such as
cables and ropes, are common in industrial assembly lines and everyday life.
These tasks are particularly challenging because they require robots to
manipulate DLO with long-horizon planning and reliable skill execution.
Successfully completing such tasks demands adapting to their nonlinear
dynamics, decomposing abstract routing goals, and generating multi-step plans
composed of multiple skills, all of which require accurate high-level reasoning
during execution. In this paper, we propose a fully autonomous hierarchical
framework for solving challenging DLO routing tasks. Given an implicit or
explicit routing goal expressed in language, our framework leverages
vision-language models~(VLMs) for in-context high-level reasoning to synthesize
feasible plans, which are then executed by low-level skills trained via
reinforcement learning. To improve robustness in long horizons, we further
introduce a failure recovery mechanism that reorients the DLO into
insertion-feasible states. Our approach generalizes to diverse scenes involving
object attributes, spatial descriptions, as well as implicit language commands.
It outperforms the next best baseline method by nearly 50% and achieves an
overall success rate of 92.5% across long-horizon routing scenarios.

</details>


### [12] [TARMAC: A Taxonomy for Robot Manipulation in Chemistry](https://arxiv.org/abs/2510.19289)
*Kefeng Huang,Jonathon Pipe,Alice E. Martin,Tianyuan Wang,Barnabas A. Franklin,Andy M. Tyrrell,Ian J. S. Fairlamb,Jihong Zhu*

Main category: cs.RO

TL;DR: 本文提出了TARMAC（化学机器人操作分类法），这是一个专门针对化学实验室的机器人操作分类框架，旨在解决现有实验室自动化系统缺乏结构化技能表示的问题，从而提高机器人的自主性和技能复用能力。


<details>
  <summary>Details</summary>
Motivation: 当前化学实验室自动化系统虽然减少了人工干预，但由于缺乏对所需操作技能的结构化表示，自主性仍然有限，大多局限于特定任务的定制解决方案，难以实现技能迁移。现有的实验抽象通常只描述协议级步骤，而没有指定执行这些步骤所需的机器人动作。

Method: 基于注释的教学实验室演示和实验验证，TARMAC根据功能角色和物理执行要求对操作进行分类，将动作定义为机器人可执行的原语，并可组合成更高级的宏操作。

Result: TARMAC提供了一个系统化的框架，用于定义和组织实验室实践中所需的核心操作，支持技能复用，并能够扩展到长期工作流程中。

Conclusion: TARMAC为更灵活和自主的实验室自动化提供了结构化基础，通过标准化的操作分类和可组合的原语，促进了机器人技能的复用和系统集成。

Abstract: Chemistry laboratory automation aims to increase throughput, reproducibility,
and safety, yet many existing systems still depend on frequent human
intervention. Advances in robotics have reduced this dependency, but without a
structured representation of the required skills, autonomy remains limited to
bespoke, task-specific solutions with little capacity to transfer beyond their
initial design. Current experiment abstractions typically describe
protocol-level steps without specifying the robotic actions needed to execute
them. This highlights the lack of a systematic account of the manipulation
skills required for robots in chemistry laboratories. To address this gap, we
introduce TARMAC - a Taxonomy for Robot Manipulation in Chemistry - a
domain-specific framework that defines and organizes the core manipulations
needed in laboratory practice. Based on annotated teaching-lab demonstrations
and supported by experimental validation, TARMAC categorizes actions according
to their functional role and physical execution requirements. Beyond serving as
a descriptive vocabulary, TARMAC can be instantiated as robot-executable
primitives and composed into higher-level macros, enabling skill reuse and
supporting scalable integration into long-horizon workflows. These
contributions provide a structured foundation for more flexible and autonomous
laboratory automation. More information is available at
https://tarmac-paper.github.io/

</details>


### [13] [Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model](https://arxiv.org/abs/2510.19356)
*Yu Fang,Xinyu Wang,Xuehe Zhang,Wanli Xue,Mingwei Zhang,Shengyong Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人模仿学习的一步捷径方法，通过多步集成来平衡推理速度和性能。该方法扩展了多步一致性损失，将一步损失拆分为多步损失，并提出了自适应梯度分配方法来解决优化不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 流匹配方法在机器人模仿学习中应用广泛，但面临推理时间高的问题。现有的蒸馏方法和一致性方法在性能上难以与原始扩散模型和流匹配模型竞争。

Method: 1. 在捷径模型基础上扩展多步一致性损失，将一步损失拆分为多步损失；2. 提出自适应梯度分配方法来解决多步损失和原始流匹配损失的优化不稳定问题。

Result: 在两个模拟基准和五个真实环境任务中评估了所提出的方法，实验结果验证了算法的有效性。

Conclusion: 该方法成功平衡了推理速度和性能，通过多步集成和自适应梯度分配提高了机器人模仿学习的效率。

Abstract: The wide application of flow-matching methods has greatly promoted the
development of robot imitation learning. However, these methods all face the
problem of high inference time. To address this issue, researchers have
proposed distillation methods and consistency methods, but the performance of
these methods still struggles to compete with that of the original diffusion
models and flow-matching models. In this article, we propose a one-step
shortcut method with multi-step integration for robot imitation learning. To
balance the inference speed and performance, we extend the multi-step
consistency loss on the basis of the shortcut model, split the one-step loss
into multi-step losses, and improve the performance of one-step inference.
Secondly, to solve the problem of unstable optimization of the multi-step loss
and the original flow-matching loss, we propose an adaptive gradient allocation
method to enhance the stability of the learning process. Finally, we evaluate
the proposed method in two simulation benchmarks and five real-world
environment tasks. The experimental results verify the effectiveness of the
proposed algorithm.

</details>


### [14] [ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling](https://arxiv.org/abs/2510.19364)
*Golnaz Raja,Ruslan Agishev,Miloš Prágr,Joni Pajarinen,Karel Zimmermann,Arun Kumar Singh,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 提出了一种高效的概率框架，用于机器人运动预测，通过显式建模空间相关的偶然不确定性并传播到可微分物理引擎中，实现概率轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 在非结构化越野环境中，地形异质性和感知不确定性高，现有方法通常假设确定性或空间独立的不确定性，忽略了3D空间数据的局部相关性，导致不可靠的预测。

Method: 使用结构化卷积算子显式建模地形参数的空间相关偶然不确定性作为概率世界模型，通过可微分物理引擎传播不确定性进行概率轨迹预测。

Result: 在公开数据集上的实验评估显示，相比偶然不确定性估计基线方法，该方法显著提高了不确定性估计和轨迹预测的准确性。

Conclusion: 该方法能够有效处理越野环境中的空间相关不确定性，为下游可穿越性估计和安全自主导航提供了更可靠的预测。

Abstract: Uncertainty-aware robot motion prediction is crucial for downstream
traversability estimation and safe autonomous navigation in unstructured,
off-road environments, where terrain is heterogeneous and perceptual
uncertainty is high. Most existing methods assume deterministic or spatially
independent terrain uncertainties, ignoring the inherent local correlations of
3D spatial data and often producing unreliable predictions. In this work, we
introduce an efficient probabilistic framework that explicitly models spatially
correlated aleatoric uncertainty over terrain parameters as a probabilistic
world model and propagates this uncertainty through a differentiable physics
engine for probabilistic trajectory forecasting. By leveraging structured
convolutional operators, our approach provides high-resolution multivariate
predictions at manageable computational cost. Experimental evaluation on a
publicly available dataset shows significantly improved uncertainty estimation
and trajectory prediction accuracy over aleatoric uncertainty estimation
baselines.

</details>


### [15] [Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets](https://arxiv.org/abs/2510.19373)
*Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher*

Main category: cs.RO

TL;DR: 提出一种简单的采样策略来缓解机器人任务数据集中物理动作不平衡的问题，该方法易于集成到现有代码库中，能提高泛化能力，在低资源任务上表现优异且不影响高资源任务性能。


<details>
  <summary>Details</summary>
Motivation: 机器人任务数据集通常基于任务描述收集，但许多任务涉及相似的物理动作序列，导致数据集在物理机器人动作表示上存在严重不平衡。

Method: 提出一种简单的采样策略，只需几行代码即可集成到现有代码库中，用于策略训练以缓解数据不平衡问题。

Result: 在预训练小模型和微调大型基础模型中都进行了评估，结果显示在低资源任务上相比现有最先进方法有显著改进，且不影响高资源任务性能，使多任务策略能更有效地利用模型容量。在Franka Panda机器人臂上的真实世界设置中也验证了该方法。

Conclusion: 该采样策略能有效解决机器人任务数据集中的动作不平衡问题，提高模型泛化能力，特别是在低资源任务上表现优异，且易于实现和集成。

Abstract: Increasingly large datasets of robot actions and sensory observations are
being collected to train ever-larger neural networks. These datasets are
collected based on tasks and while these tasks may be distinct in their
descriptions, many involve very similar physical action sequences (e.g., 'pick
up an apple' versus 'pick up an orange'). As a result, many datasets of robotic
tasks are substantially imbalanced in terms of the physical robotic actions
they represent. In this work, we propose a simple sampling strategy for policy
training that mitigates this imbalance. Our method requires only a few lines of
code to integrate into existing codebases and improves generalization. We
evaluate our method in both pre-training small models and fine-tuning large
foundational models. Our results show substantial improvements on low-resource
tasks compared to prior state-of-the-art methods, without degrading performance
on high-resource tasks. This enables more effective use of model capacity for
multi-task policies. We also further validate our approach in a real-world
setup on a Franka Panda robot arm across a diverse set of tasks.

</details>


### [16] [Risk Assessment of an Autonomous Underwater Snake Robot in Confined Operations](https://arxiv.org/abs/2510.19415)
*Abdelrahman Sayed Sayed*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯方法来评估Eely水下机器人在两种任务场景中丢失的风险，旨在提高Eely的性能和任务成功率，并通过敏感性分析识别对丢失风险影响最大的因素。


<details>
  <summary>Details</summary>
Motivation: 海洋探测需求的增长要求在受限和苛刻环境中进行检查和干预，Eely的细长形状和改变身体配置的能力使其成为适合此类环境的选项，但操作Eely面临不确定和非结构化环境、极端环境条件和降低的导航能力等挑战。

Method: 采用贝叶斯方法来评估Eely在两种任务场景中的丢失风险，并进行敏感性分析以识别关键影响因素。

Result: 通过敏感性分析展示了导致Eely丢失影响最大的原因。

Conclusion: 贝叶斯风险评估方法有助于提高Eely水下机器人的性能和任务成功率。

Abstract: The growing interest in ocean discovery imposes a need for inspection and
intervention in confined and demanding environments. Eely's slender shape, in
addition to its ability to change its body configurations, makes articulated
underwater robots an adequate option for such environments. However, operation
of Eely in such environments imposes demanding requirements on the system, as
it must deal with uncertain and unstructured environments, extreme
environmental conditions, and reduced navigational capabilities. This paper
proposes a Bayesian approach to assess the risks of losing Eely during two
mission scenarios. The goal of this work is to improve Eely's performance and
the likelihood of mission success. Sensitivity analysis results are presented
in order to demonstrate the causes having the highest impact on losing Eely.

</details>


### [17] [GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430)
*GigaBrain Team,Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu*

Main category: cs.RO

TL;DR: GigaBrain-0是一个基于世界模型生成数据的视觉-语言-动作基础模型，通过生成多样化数据减少对真实机器人数据的依赖，提升跨任务泛化能力，并在真实世界任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言-动作模型训练需要大规模真实机器人数据的问题，这些数据收集成本高、耗时长，限制了VLA系统的可扩展性和泛化能力。

Method: 利用世界模型生成多样化数据（视频生成、真实到真实传输、人类传输、视角传输、仿真到真实传输数据），结合RGBD输入建模和具身思维链监督，增强模型对空间几何、物体状态和长时依赖关系的推理能力。

Result: 在灵巧操作、长时程任务和移动操作任务中取得显著性能提升，在外观、物体放置和相机视角变化方面表现出优异的泛化能力，并开发了轻量级版本GigaBrain-0-Small。

Conclusion: GigaBrain-0通过世界模型生成数据有效解决了真实机器人数据稀缺问题，显著提升了VLA模型的泛化能力和实际性能，为机器人学习提供了可扩展的解决方案。

Abstract: Training Vision-Language-Action (VLA) models for generalist robots typically
requires large-scale real-world robot data, which is expensive and
time-consuming to collect. The inefficiency of physical data collection
severely limits the scalability, and generalization capacity of current VLA
systems. To address this challenge, we introduce GigaBrain-0, a novel VLA
foundation model empowered by world model-generated data (e.g., video
generation, real2real transfer, human transfer, view transfer, sim2real
transfer data). By leveraging world models to generate diverse data at scale,
GigaBrain-0 significantly reduces reliance on real robot data while improving
cross-task generalization. Our approach further improves policy robustness
through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision,
enabling the model to reason about spatial geometry, object states, and
long-horizon dependencies during task execution. This leads to substantial
gains in real-world performance on dexterous, long-horizon, and mobile
manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves
superior generalization across variations in appearances (e.g., textures,
colors), object placements, and camera viewpoints. Additionally, we present
GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently
on devices such as the NVIDIA Jetson AGX Orin.

</details>


### [18] [Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning](https://arxiv.org/abs/2510.19495)
*Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta*

Main category: cs.RO

TL;DR: 本文提出通过离线强化学习有效利用非专家数据来增强模仿学习策略性能的方法，解决了传统模仿学习对高质量专家数据依赖的问题。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习依赖高质量专家数据，限制了在多样化现实场景中的适应性。非专家数据（如游戏数据、次优演示等）具有更广覆盖和更低收集成本，但现有方法无法有效利用。

Method: 采用离线强化学习作为工具，通过简单的算法修改来利用非专家数据，包括扩展策略分布支持范围等技术，无需额外强假设。

Result: 在操作任务中，该方法显著提高了学习策略在更广泛初始条件下的成功率，增强了恢复和泛化能力，能够有效利用所有收集数据（包括部分或次优演示）来提升任务导向策略性能。

Conclusion: 算法技术对于利用非专家数据进行鲁棒策略学习在机器人领域具有重要意义，离线强化学习可以成为有效利用非专家数据的工具。

Abstract: Imitation learning has proven effective for training robots to perform
complex tasks from expert human demonstrations. However, it remains limited by
its reliance on high-quality, task-specific data, restricting adaptability to
the diverse range of real-world object configurations and scenarios. In
contrast, non-expert data -- such as play data, suboptimal demonstrations,
partial task completions, or rollouts from suboptimal policies -- can offer
broader coverage and lower collection costs. However, conventional imitation
learning approaches fail to utilize this data effectively. To address these
challenges, we posit that with right design decisions, offline reinforcement
learning can be used as a tool to harness non-expert data to enhance the
performance of imitation learning policies. We show that while standard offline
RL approaches can be ineffective at actually leveraging non-expert data under
the sparse data coverage settings typically encountered in the real world,
simple algorithmic modifications can allow for the utilization of this data,
without significant additional assumptions. Our approach shows that broadening
the support of the policy distribution can allow imitation algorithms augmented
by offline RL to solve tasks robustly, showing considerably enhanced recovery
and generalization behavior. In manipulation tasks, these innovations
significantly increase the range of initial conditions where learned policies
are successful when non-expert data is incorporated. Moreover, we show that
these methods are able to leverage all collected data, including partial or
suboptimal demonstrations, to bolster task-directed policy performance. This
underscores the importance of algorithmic techniques for using non-expert data
for robust policy learning in robotics.

</details>


### [19] [Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach](https://arxiv.org/abs/2510.19541)
*Francesco Schetter,Shifa Sulaiman,Shoby George,Paolino De Risi,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型预测控制（MPC）的策略，用于调节连接到肌腱驱动假肢手的软连续腕部运动，通过预测建模实现精确运动调整，显著提高假肢手的灵活性和自然度。


<details>
  <summary>Details</summary>
Motivation: 将先进控制策略集成到假肢手中对于提高其适应性和性能至关重要，MPC在增强假肢手功能和响应性方面发挥关键作用。

Method: 使用Euler-Bernoulli梁进行运动学建模，Lagrange方法进行动力学建模，实施模型预测控制策略来调节软连续腕部运动。

Result: 通过仿真和实验验证，证明MPC在优化腕部关节和用户控制方面的有效性，显著提高假肢手的灵活性，使运动更加自然直观。

Conclusion: 这项研究为智能假肢系统提供了一个有前景的方向，对机器人技术和生物医学工程领域做出了贡献。

Abstract: The integration of advanced control strategies into prosthetic hands is
essential to improve their adaptability and performance. In this study, we
present an implementation of a Model Predictive Control (MPC) strategy to
regulate the motions of a soft continuum wrist section attached to a
tendon-driven prosthetic hand with less computational effort. MPC plays a
crucial role in enhancing the functionality and responsiveness of prosthetic
hands. By leveraging predictive modeling, this approach enables precise
movement adjustments while accounting for dynamic user interactions. This
advanced control strategy allows for the anticipation of future movements and
adjustments based on the current state of the prosthetic device and the
intentions of the user. Kinematic and dynamic modelings are performed using
Euler-Bernoulli beam and Lagrange methods respectively. Through simulation and
experimental validations, we demonstrate the effectiveness of MPC in optimizing
wrist articulation and user control. Our findings suggest that this technique
significantly improves the prosthetic hand dexterity, making movements more
natural and intuitive. This research contributes to the field of robotics and
biomedical engineering by offering a promising direction for intelligent
prosthetic systems.

</details>


### [20] [LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments](https://arxiv.org/abs/2510.19655)
*Hongyu Ding,Ziming Xu,Yudong Fang,You Wu,Zixuan Chen,Jieqi Shi,Jing Huo,Yifan Zhang,Yang Gao*

Main category: cs.RO

TL;DR: LaViRA是一个零样本视觉语言导航框架，通过将动作分解为语言动作、视觉动作和机器人动作三个层次，利用不同规模的多模态大语言模型在各自阶段的优势，在未见环境中实现卓越的导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决零样本视觉语言导航中环境特定路径点预测器限制场景泛化能力，以及大模型在导航过程中推理能力未被充分利用的问题。

Method: 提出LaViRA框架，采用粗到细的动作层次分解：语言动作用于高层规划，视觉动作用于感知接地，机器人动作用于鲁棒导航，利用不同规模MLLM在各阶段的优势。

Result: 在VLN-CE基准测试中显著优于现有最先进方法，在未见环境中展现出卓越的泛化能力。

Conclusion: LaViRA通过模块化分解实现了强大的推理、接地和实际控制能力，同时保持透明度和效率，适合实际部署。

Abstract: Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
requires an agent to navigate unseen environments based on natural language
instructions without any prior training. Current methods face a critical
trade-off: either rely on environment-specific waypoint predictors that limit
scene generalization, or underutilize the reasoning capabilities of large
models during navigation. We introduce LaViRA, a simple yet effective zero-shot
framework that addresses this dilemma by decomposing action into a
coarse-to-fine hierarchy: Language Action for high-level planning, Vision
Action for perceptual grounding, and Robot Action for robust navigation. This
modular decomposition allows us to leverage the distinct strengths of different
scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
system that is powerful in its reasoning, grounding and practical control.
LaViRA significantly outperforms existing state-of-the-art methods on the
VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
environments, while maintaining transparency and efficiency for real-world
deployment.

</details>


### [21] [Fast Marker Detection for UV-Based Visual Relative Localisation in Agile UAV Swarms](https://arxiv.org/abs/2510.19663)
*Vojtěch Vrba,Viktor Walter,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 本文提出了一种用于敏捷无人机群中多队友视觉相对定位的快速机载孤立标记检测方法，包含CPU优化程序、GPU着色器程序和FPGA流架构三种创新方案，处理速度比现有技术快2-3个数量级。


<details>
  <summary>Details</summary>
Motivation: 为满足敏捷无人机群实时定位系统的关键需求，需要快速检测孤立标记以实现多队友之间的视觉相对定位。

Method: 提出了三种创新方案：CPU优化程序、GPU着色器程序和功能等效的FPGA流架构，并在多种32位和64位嵌入式平台上进行评估。

Result: CPU和GPU解决方案的每像素平均处理时间比现有技术快2-3个数量级，FPGA架构通过最小化从相机曝光到检测结果的总延迟提供了最显著的总体加速。

Conclusion: 该技术已成为敏捷无人机群的关键使能技术，证明了在低端无人机和MAV应用中的效率和可行性。

Abstract: A novel approach for the fast onboard detection of isolated markers for
visual relative localisation of multiple teammates in agile UAV swarms is
introduced in this paper. As the detection forms a key component of real-time
localisation systems, a three-fold innovation is presented, consisting of an
optimised procedure for CPUs, a GPU shader program, and a functionally
equivalent FPGA streaming architecture. For the proposed CPU and GPU solutions,
the mean processing time per pixel of input camera frames was accelerated by
two to three orders of magnitude compared to the state of the art. For the
localisation task, the proposed FPGA architecture offered the most significant
overall acceleration by minimising the total delay from camera exposure to
detection results. Additionally, the proposed solutions were evaluated on
various 32-bit and 64-bit embedded platforms to demonstrate their efficiency,
as well as their feasibility for applications using low-end UAVs and MAVs.
Thus, it has become a crucial enabling technology for agile UAV swarming.

</details>


### [22] [Learning Affordances at Inference-Time for Vision-Language-Action Models](https://arxiv.org/abs/2510.19752)
*Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine*

Main category: cs.RO

TL;DR: LITEN方法通过连接VLA低级策略和高级VLM，利用过去执行经验进行上下文学习，实现机器人任务失败后的动态行为调整。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型缺乏在任务失败时上下文动态调整行为的能力，无法像人类一样从失败中学习并改进策略。

Method: 将VLA低级策略连接到高级VLM，通过推理阶段生成执行计划，评估阶段反思执行结果并提取有用结论，将经验纳入后续推理上下文。

Result: 实验结果显示LITEN能够有效从过去经验中学习，生成使用高可用性指令完成长时程任务的计划。

Conclusion: LITEN通过连接高低级模型并利用执行时学习，显著提升了机器人处理复杂控制任务的能力。

Abstract: Solving complex real-world control tasks often takes multiple tries: if we
fail at first, we reflect on what went wrong, and change our strategy
accordingly to avoid making the same mistake. In robotics,
Vision-Language-Action models (VLAs) offer a promising path towards solving
complex control tasks, but lack the ability to contextually and dynamically
readjust behavior when they fail to accomplish a task. In this work, we
introduce Learning from Inference-Time Execution (LITEN), which connects a VLA
low-level policy to a high-level VLM that conditions on past experiences by
including them in-context, allowing it to learn the affordances and
capabilities of the low-level VLA. Our approach iterates between a reasoning
phase that generates and executes plans for the low-level VLA, and an
assessment phase that reflects on the resulting execution and draws useful
conclusions to be included in future reasoning contexts. Unlike similar
approaches to self-refinement in non-robotics domains, LITEN must reflect on
unstructured real-world robot trajectories (e.g., raw videos), which requires
structured guiderails during assessment. Our experimental results demonstrate
LITEN is able to effectively learn from past experience to generate plans that
use high-affordance instructions to accomplish long-horizon tasks.

</details>


### [23] [SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas](https://arxiv.org/abs/2510.19766)
*Hongyu Ding,Xinyue Liang,Yudong Fang,You Wu,Jieqi Shi,Jing Huo,Wenbin Li,Jing Wu,Yu-Kun Lai,Yang Gao*

Main category: cs.RO

TL;DR: 提出SEA方法，通过语义地图预测和基于强化学习的层次探索策略进行主动机器人探索，显著优于现有最先进方法


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法依赖单步路径点预测，缺乏长期环境理解，导致探索效率不高

Method: 采用迭代预测-探索框架，基于当前观测预测地图缺失区域，利用实际地图与预测全局地图的差异指导探索，设计基于强化学习的奖励机制更新长期探索策略

Result: 实验结果表明该方法在相同时间限制下显著优于现有最先进探索策略，获得更优的全局地图覆盖范围

Conclusion: SEA方法通过语义地图预测和强化学习层次策略有效提升了机器人探索的效率和准确性

Abstract: In this paper, we propose SEA, a novel approach for active robot exploration
through semantic map prediction and a reinforcement learning-based hierarchical
exploration policy. Unlike existing learning-based methods that rely on
one-step waypoint prediction, our approach enhances the agent's long-term
environmental understanding to facilitate more efficient exploration. We
propose an iterative prediction-exploration framework that explicitly predicts
the missing areas of the map based on current observations. The difference
between the actual accumulated map and the predicted global map is then used to
guide exploration. Additionally, we design a novel reward mechanism that
leverages reinforcement learning to update the long-term exploration
strategies, enabling us to construct an accurate semantic map within limited
steps. Experimental results demonstrate that our method significantly
outperforms state-of-the-art exploration strategies, achieving superior
coverage ares of the global map within the same time constraints.

</details>
