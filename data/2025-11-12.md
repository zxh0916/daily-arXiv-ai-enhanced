<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Time-Aware Policy Learning for Adaptive and Punctual Robot Control](https://arxiv.org/abs/2511.07654)
*Yinsen Jia,Boyuan Chen*

Main category: cs.RO

TL;DR: 本文提出了一种时间感知策略学习框架，通过将剩余时间和时间比率作为额外信号，使机器人能够将时间作为第一类变量进行感知和推理，从而在单一策略中实现从快速动态到谨慎精确的连续行为调节。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器人学习算法对时间感知不足，而时间意识是动物和人类智能行为的基础。为了赋予机器人明确的时间感知和推理能力，使其能够根据时间约束自适应调整行为。

Method: 在传统强化学习策略基础上引入两个互补的时间信号：剩余时间和时间比率，通过联合优化准时性和稳定性，使机器人能够在无需重新训练或奖励调整的情况下平衡效率、鲁棒性、弹性和准时性。

Result: 在多种操作任务中，时间感知策略相比标准强化学习基线在效率上提升高达48%，在仿真到现实迁移中鲁棒性提高8倍，声学安静度提升90%，同时保持接近完美的成功率。

Conclusion: 通过将时间视为行为的可控维度而非约束，时间感知策略学习为高效、鲁棒、弹性和人类对齐的机器人自主性提供了统一基础，进一步支持实时人机交互控制和多智能体协调。

Abstract: Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.

</details>


### [2] [A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake](https://arxiv.org/abs/2511.08005)
*Huacen Wang,Hongqiang Wang*

Main category: cs.RO

TL;DR: 本文提出了一种具有集成制动功能的两层静电薄膜执行器，通过在顶层和底层交替分布电极，在相同制造约束下实现更小的有效电极间距，使驱动力达到约241 N/m²，比之前的三相执行器提高了90.5%。


<details>
  <summary>Details</summary>
Motivation: 传统电机驱动的机器人系统存在质量大、控制算法复杂、需要额外制动机制等问题，限制了其在轻量紧凑机器人平台的应用。静电薄膜执行器虽然具有薄、柔、轻、高开环定位精度等优点，但传统三相电极设计的驱动力仍有待提高。

Method: 设计了两层静电薄膜执行器，在顶层和底层交替分布电极，实现更小的有效电极间距。同时集成了静电粘附机制，可在制动模式下保持负载。

Result: 执行器驱动力达到约241 N/m²，比之前的三相执行器提高了90.5%。通过多个演示验证了其在驱动和制动模式下的优越性能，包括与传统单层执行器的拔河测试、负载操作、单自由度机械臂和双模式夹爪。

Conclusion: 所提出的两层静电薄膜执行器在驱动力方面显著优于传统设计，同时集成的制动功能使其在轻量紧凑机器人应用中具有重要价值。

Abstract: Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.

</details>


### [3] [Model Predictive Control via Probabilistic Inference: A Tutorial](https://arxiv.org/abs/2511.08019)
*Kohei Honda*

Main category: cs.RO

TL;DR: 本文提供了基于概率推理的模型预测控制教程，将最优控制重新解释为概率推理问题，使用采样技术估计最优控制分布，能够处理任意成本函数和动态系统。


<details>
  <summary>Details</summary>
Motivation: 传统数值优化方法在处理机器人学中常见的非线性或不可微系统时往往难以处理，而基于概率推理的MPC方法通过采样技术可以处理任意成本函数和动态系统。

Method: 推导最优控制分布的概率解释，以模型预测路径积分控制算法为例，讨论先验和变分分布设计、调优原则和理论方面。

Result: 建立了基于概率推理的MPC统一理论框架，提供了代表性方法的全面概述，特别是MPPI算法作为实际应用示例。

Conclusion: 本文旨在为研究人员和从业者提供系统指南，帮助理解、实现和扩展这些方法在机器人学及其他领域的应用。

Abstract: Model Predictive Control (MPC) is a fundamental framework for optimizing robot behavior over a finite future horizon. While conventional numerical optimization methods can efficiently handle simple dynamics and cost structures, they often become intractable for the nonlinear or non-differentiable systems commonly encountered in robotics. This article provides a tutorial on probabilistic inference-based MPC, presenting a unified theoretical foundation and a comprehensive overview of representative methods. Probabilistic inference-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have gained significant attention by reinterpreting optimal control as a problem of probabilistic inference. Rather than relying on gradient-based numerical optimization, these methods estimate optimal control distributions through sampling-based techniques, accommodating arbitrary cost functions and dynamics. We first derive the optimal control distribution from the standard optimal control problem, elucidating its probabilistic interpretation and key characteristics. The widely used MPPI algorithm is then derived as a practical example, followed by discussions on prior and variational distribution design, tuning principles, and theoretical aspects. This article aims to serve as a systematic guide for researchers and practitioners seeking to understand, implement, and extend these methods in robotics and beyond.

</details>
