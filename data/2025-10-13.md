<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 提出了一种结合大语言模型推理能力和局部搜索的接触点选择方法ConPoSe，用于解决多机器人协作推物体时的接触点选择问题，相比传统解析方法和纯LLM方法具有更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中进行物体运输是服务机器人和仓储物流的基本任务。多机器人协作运输大型物体时，推物体策略只需要简单的机器人，但需要仔细选择机器人与物体的接触点以确保沿预定路径移动。虽然解析方法可以解决这个问题，但随着机器人数量和物体尺寸的增加，解空间呈组合式增长，限制了可扩展性。

Method: 受人类依赖常识推理进行协作运输的启发，提出将大语言模型的推理能力与局部搜索相结合来选择合适的接触点。开发了LLM引导的局部搜索方法ConPoSe用于接触点选择。

Result: ConPoSe成功为各种形状（包括长方体、圆柱体和T形）选择了接触点。实验表明，ConPoSe在机器人数量和物体尺寸方面的可扩展性优于解析方法，并且也优于纯基于LLM的选择方法。

Conclusion: 结合大语言模型推理和局部搜索的ConPoSe方法能够有效解决多机器人协作推物体时的接触点选择问题，具有良好的可扩展性和性能表现。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [2] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 提出Point and Go模式切换方法，通过重新分配笛卡尔模式切换参考帧到更直观的动作空间，包含新的平移和旋转模式，显著提升轮椅机械臂的操作性能。


<details>
  <summary>Details</summary>
Motivation: 传统笛卡尔空间模式切换存在控制参考帧不直观、平移和旋转控制分离、运动能力有限等问题，影响轮椅机械臂用户的操作性能。

Method: 使用新颖的扫掠运动指向夹具，在机器人基座坐标系水平面定义新的平移轴，创建直观的'指向并移动'平移模式；旋转模式结合位置控制和精炼的末端执行器定向框架。

Result: 相比笛卡尔模式切换和最先进学习方法，Point and Go模式切换将完成时间减少31%，暂停时间减少41%，模式切换次数减少33%，用户调查反馈显著更优。

Conclusion: Point and Go模式切换通过更直观的动作空间设计，显著提升了轮椅机械臂的操作效率和用户体验，是解决高自由度机器人控制难题的有效方法。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [3] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 开发了一个让四足机器人打动态乒乓球的系统，集成了高速感知、轨迹预测和敏捷控制，能够在真实世界的Spot四足机器人上实现与人类玩家的对打。


<details>
  <summary>Details</summary>
Motivation: 开发能够匹配人类速度、精度，并能预测和响应各种球旋转的乒乓球机器人对腿式机器人来说仍是一个重大挑战。

Method: 使用外部摄像头进行高速球定位，结合物理模型和学习的残差来推断旋转和预测轨迹，并采用新颖的模型预测控制（MPC）公式进行敏捷的全身控制。

Result: 系统在真实世界的Spot四足机器人上成功演示，能够瞄准并回击不同类型旋转的球，并能与人类玩家进行对打。

Conclusion: 该系统展示了四足机器人在动态乒乓球任务中的协调能力，自动涌现出连续的击球策略，为腿式机器人的敏捷控制提供了新的可能性。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [4] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: GPI将演示数据视为几何曲线而非状态-动作样本，通过距离场生成两个互补的控制原语：前进流和吸引流，形成可控制的非参数向量场直接指导机器人行为。


<details>
  <summary>Details</summary>
Motivation: 重新思考模仿学习，将演示数据作为几何曲线处理，解耦度量学习和策略合成，实现跨低维机器人状态和高维感知输入的模块化适应。

Method: 从演示曲线推导距离场，生成前进流（沿专家轨迹推进）和吸引流（纠正偏差）两个控制原语，组合成可控的非参数向量场。

Result: 在仿真和真实机器人上的实验表明，GPI比基于扩散的策略获得更高的成功率，运行速度快20倍，内存需求更少，且对扰动具有鲁棒性。

Conclusion: GPI为机器人模仿学习提供了一种高效、可解释且可扩展的替代生成方法的方法。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [5] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出了Humanoid Everyday数据集，这是一个大规模、多样化的人形机器人操作数据集，包含10.3k条轨迹和300多万帧数据，涵盖260个任务和7个主要类别，并提供了云端评估平台。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习数据集主要关注固定机械臂，现有人形机器人数据集要么局限于固定环境，要么任务多样性不足，缺乏人机交互和下半身运动，且缺少标准化评估平台。

Method: 使用高效的人监督遥操作流水线收集高质量多模态感官数据（RGB、深度、LiDAR、触觉输入）和自然语言标注，构建大规模数据集。

Result: 创建了包含10.3k轨迹、300多万帧数据的多样化数据集，涵盖灵巧物体操作、人机交互、运动集成动作等260个任务，并建立了云端评估平台。

Conclusion: 通过发布Humanoid Everyday数据集、策略学习分析和标准化云端评估平台，旨在推动通用人形机器人操作研究，为现实场景中更强大的具身智能体奠定基础。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [6] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于物理接触的自适应运动规划框架，通过从物理接触中推断人类意图，实现人机协作中的在线运动校正。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人如何适应人类意图的问题，克服大语言模型在可靠运动规划中的局限性，以及传统物理人机交互中持续引导带来的操作负担。

Method: 1) 基于优化的力估计方法，从关节扭矩测量和机器人动力学模型推断人类意图的接触力和位置；2) 基于扭矩的接触检测机制，实现链接级定位；3) 接触感知的自适应运动规划器，在线重新规划机器人运动。

Result: 在7自由度机械臂上的实验表明，所提出的力估计方法具有准确性，接触感知自适应运动规划器在人机协作中感知不确定性的情况下具有有效性。

Conclusion: 该框架能够直接从物理接触中推断人类意图，实现实时运动校正，为人机协作提供了一种可靠且高效的解决方案。

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [7] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: 提出概念驱动探索（CDE）方法，利用预训练视觉语言模型从文本任务描述生成物体中心视觉概念，通过概念重构作为内在奖励来指导视觉强化学习中的探索。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习中的智能探索面临挑战，需要从原始像素中提取任务相关结构，导致探索效率低下。

Method: 使用预训练视觉语言模型生成物体中心视觉概念作为弱监督信号，训练策略通过辅助目标重构这些概念，将重构精度作为内在奖励来指导探索。

Result: 在五个模拟视觉操作任务中，CDE实现了高效、有针对性的探索，对噪声VLM预测具有鲁棒性，并在真实世界Franka机械臂上达到80%的成功率。

Conclusion: CDE方法有效解决了视觉强化学习中的探索问题，通过概念重构内在奖励实现了任务相关的探索，且部署时不依赖外部模型。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [8] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 本文提出了一种紧密耦合的在线校准方法，融合IMU、里程计和原始GNSS测量数据，用于自主地面车辆的定位校准。该方法在可扩展因子图优化框架中实现，包含异常值缓解和模糊度解析功能。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS辅助方法通常依赖定位结果或未解析模糊度的原始测量，且其可观测性特性研究不足。需要开发更精确的校准方法来提高自主地面车辆的定位性能。

Method: 紧密耦合在线校准方法，在可扩展因子图优化框架中融合IMU、里程计和原始GNSS测量数据（伪距、载波相位和多普勒），包含异常值缓解和模糊度解析功能。

Result: 仿真和真实世界实验表明，该方法在校准和定位性能上优于最先进的松耦合方法。使用校准参数的IMU-里程计定位绝对最大误差为17.75米，而松耦合方法为61.51米，性能提升达71.14%。

Conclusion: 该方法显著提高了校准和定位精度，并发布了首个结合IMU、2D里程计以及来自流动站和基站原始GNSS测量的开源数据集，以促进进一步研究。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [9] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 该论文提出了一种混合强化学习框架，结合了无模型和基于模型的强化学习方法，用于改进机器人手内操作任务的性能。通过轨迹评估指导训练好的策略，在大多数测试案例中提升了操作性能，但增加了计算成本。


<details>
  <summary>Details</summary>
Motivation: 手内操作是机器人学中的难点挑战，涉及复杂动态系统和对各种物体的精确控制。本研究旨在验证先前开发的混合强化学习框架在手内操作任务中的应用效果，探索其性能提升能力。

Method: 采用混合强化学习框架，结合无模型和基于模型的方法。通过动态模型和价值函数进行轨迹评估来指导训练好的策略，类似于模型预测控制。使用全驱动和欠驱动模拟机器人手操作不同物体进行测试。

Result: 实验结果表明，在具有高平均奖励的策略和准确动态模型的情况下，混合框架在大多数测试案例中改进了手内操作任务的性能，即使物体属性发生变化时也能保持改进。

Conclusion: 混合强化学习框架能够有效提升手内操作任务的性能，但需要权衡性能改进与计算成本增加之间的关系，因为轨迹评估的复杂性导致了更高的计算开销。

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [10] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文开发并验证了数据驱动的预测控制（DeePC）框架在3D软体机器人控制中的应用，通过实验证明其在固定点调节和轨迹跟踪任务中优于传统模型控制方法。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有安全性和适应性优势，但由于其复杂的非线性动力学特性，实现精确动态控制仍面临挑战。DeePC作为一种无需显式系统识别的模型无关方法，在软体机器人领域的应用尚未充分探索。

Method: 设计制造了具有厚管状骨架、致密硅胶体和刚性端盖的3D电缆驱动软体臂，采用基于奇异值分解的维度缩减技术实现DeePC控制框架。

Result: 与基线模型控制器相比，DeePC在3D空间中的固定点调节和轨迹跟踪任务中表现出更高的精度、鲁棒性和适应性。

Conclusion: DeePC框架为软体机器人的动态控制提供了实用解决方案，展示了其在复杂非线性系统中的控制潜力。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [11] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种将一般二次曲面分类为轴对称二次曲面（AQ）的方法，并解决了点到AQ的邻近度问题。该问题从R^3简化为R^2，并基于圆锥曲线的几何特性提出了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决三维空间中点到轴对称二次曲面的邻近度计算问题，现有文献中缺乏将问题从R^3简化为R^2的有效方法。

Method: 将R^3中的邻近度问题简化为R^2，利用圆锥曲线的几何特性（如次法线、半长轴长度、偏心率、斜率和半径）开发新算法，并根据点的位置将问题进一步分类为抛物线和椭圆/双曲线的子情况。

Result: 提出的方法适合在C等编程语言中实现，并且比商业库Bullet更快。

Conclusion: 该方法成功解决了点到轴对称二次曲面的邻近度计算问题，通过降维和几何特性分析实现了高效计算，具有实际应用价值。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [12] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 该论文提出了一种基于切换线性系统的监督者信任动态模型，该模型能够处理对自主系统性能的不对称响应和间歇性通信特性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏能够处理自主系统性能不对称响应和间歇性通信的监督者信任动态模型，这影响了人类监督者与自主系统之间的交互质量。

Method: 采用切换线性系统结构，结合事件触发采样机制，构建监督者信任估计模型，并通过51名参与者的用户研究数据来识别模型参数。

Result: 开发了一个基于切换线性模型的监督者信任观测器，能够有效捕捉信任动态变化。

Conclusion: 所提出的模型框架能够更好地描述监督者信任的动态特性，为改善人机交互质量提供了理论基础。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [13] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: iMoWM是一个用于机器人操作的交互式世界模型，通过多模态令牌化器统一输入，能够自回归生成彩色图像、深度图和机器人手臂掩码，为基于模型的强化学习和模仿学习提供有效模拟器。


<details>
  <summary>Details</summary>
Motivation: 现有的2D视频世界模型缺乏几何和空间推理能力，无法捕捉3D世界的物理结构，限制了在机器人操作中的应用。

Method: 提出iMoWM交互式世界模型和MMTokenizer多模态令牌化器，将多模态输入统一为紧凑令牌表示，利用预训练VideoGPT模型实现高效的多模态预测。

Result: 实验证明iMoWM在视觉质量、基于模型的强化学习和真实世界模仿学习任务中表现出优越性能。

Conclusion: 多模态世界建模为机器人操作提供了更丰富的物理信息，显著提升了预测质量和实际应用效果。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [14] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 使用机器学习从人类反应中识别机器人连续失败阶段，通过视频行为特征训练个性化模型，在检测错误和分类连续失败方面分别达到93.5%和84.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人更深入融入社会，检测机器人错误对于有效的人机交互至关重要。人类对机器人错误的反应会随着连续失败而加剧，从困惑到明显沮丧，这些演化反应能揭示连续失败。

Method: 在26名参与者与犯重复对话错误的机器人互动研究中，从视频数据中提取行为特征，为个体用户训练机器学习模型。

Result: 最佳模型在检测错误方面达到93.5%的准确率，在分类连续失败方面达到84.1%的准确率。

Conclusion: 建模人类反应的进展过程能增强错误检测能力，并更好地理解人机交互中重复的交互中断问题。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [15] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的视觉教-重复导航系统，通过灵活的地图表示、鲁棒的地图匹配和无地图局部导航模块，解决了环境变化和动态物体对轨迹重复导航的挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉教-重复导航是移动机器人在未知环境中部署的直接解决方案，但由于环境变化和动态物体的存在，鲁棒的轨迹重复导航仍然面临挑战。

Method: 系统包括灵活的地图表示（拓扑度量图）、基于关键帧聚类的帧到局部地图匹配策略、长期目标管理算法以及无地图局部轨迹控制候选优化算法。

Result: 在移动平台上进行的广泛实验表明，该系统在鲁棒性和有效性方面优于基线方法。

Conclusion: 所提出的视觉教-重复导航系统能够有效应对环境变化和动态障碍物，实现鲁棒的轨迹重复导航。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [16] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 该论文提出了一种从受限专家演示中学习的方法，通过推断状态奖励信号和自标注未知状态奖励，使机器人能够探索比演示更高效的轨迹，从而超越直接模仿学习。


<details>
  <summary>Details</summary>
Motivation: 传统从演示学习的方法由于专家受到间接控制、设置限制和硬件安全等约束，无法展示最优行为，导致学习到的策略性能不佳。需要解决机器人能否学习比受限专家演示更好的策略的问题。

Method: 使用演示推断仅基于状态的任务进度奖励信号，并通过时间插值为未知状态自标注奖励，允许智能体超越直接模仿专家动作，探索更短更高效的轨迹。

Result: 该方法在样本效率和任务完成时间上均优于常见的模仿学习方法。在真实的WidowX机械臂上，任务完成时间仅需12秒，比行为克隆快10倍。

Conclusion: 通过推断状态奖励和自标注奖励的方法，机器人能够从受限专家的演示中学习到比演示本身更优的策略，显著提高了任务执行效率。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [17] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的分层相对导航框架，在未知、结构受限且无GPS的环境中实现战略远见和战术敏捷性，无需统一坐标系。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在未知、结构受限、无GPS环境中的导航问题，平衡全局战略远见与局部战术敏捷性之间的基本权衡，特别是在通信受限情况下。

Method: 采用分层相对导航框架：战略层通过机会性相遇构建和交换轻量级拓扑地图，培养涌现的全局意识；战术层基于局部度量信息，使用基于采样的逃逸点策略实时生成动态可行轨迹。

Result: 广泛的仿真和真实世界实验表明，该系统在成功率和高效率方面显著优于其他方法，特别是在具有复杂拓扑结构的通信受限环境中。

Conclusion: 该框架成功实现了在无统一坐标系情况下的战略远见和战术敏捷性，有效解决了多机器人导航中的死锁和拓扑陷阱问题。

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [18] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 开发了一种轻量级电动假手，仅使用4个电机实现基本抓握姿势和手内操作（精度和侧向抓握之间的重新定向），重量仅311克，成功率达到90-100%。


<details>
  <summary>Details</summary>
Motivation: 电动假手需要轻量化以减轻用户负担，外形像人手用于美观，电机内置以保护免受损坏和污垢。除了执行日常活动的能力外，这些特性对于日常使用至关重要。手内操作对于执行日常活动是必要的，例如在不同姿势之间转换，特别是通过旋转运动。

Method: 结合单轴拇指和优化的拇指定位，仅使用四个电机在轻量级假手中实现基本姿势和手内操作（精度和侧向抓握之间的重新定向）。

Result: 使用各种宽度（5-30毫米）和形状（圆柱体和棱柱）的原始物体进行实验验证，重新定向任务的成功率达到90-100%。该手能够执行印章盖印和USB设备插入，以及旋转操作螺丝刀。

Conclusion: 通过单轴拇指和优化的拇指定位，仅使用四个电机在轻量级假手中成功实现了基本抓握姿势和手内操作，为日常使用的电动假手提供了一种可行的解决方案。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [19] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: HANDO是一个双层框架，用于配备机械臂的腿式机器人执行以人为中心的移动操作任务，包括自主导航和全身协调操作。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现无缝的移动操作需要机器人结合自主探索和全身控制进行物理交互。

Method: 第一层使用目标条件自主探索策略引导机器人到达语义指定目标；第二层采用统一的全身移动操作策略协调手臂和腿部进行精确交互任务。

Result: 已完成导航模块的初步部署，将继续推进全身移动操作的更精细部署。

Conclusion: HANDO框架展示了腿式机器人在动态环境中执行复杂移动操作任务的潜力。

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [20] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: Glovity是一个低成本的可穿戴遥操作系统，集成了空间力反馈设备和带有指尖霍尔传感器校准的触觉手套，能够实现反馈丰富的灵巧操作。该系统通过提供直观的力反馈和触觉反馈解决接触密集任务中的关键挑战，并通过精确重定向克服体现差距。


<details>
  <summary>Details</summary>
Motivation: 解决接触密集任务中的关键挑战，提供直观的力反馈和触觉反馈，同时通过精确重定向克服体现差距，实现反馈丰富的灵巧操作。

Method: 集成空间力反馈设备与带有指尖霍尔传感器校准的触觉手套，提供直观的力反馈和触觉反馈，并通过精确重定向克服体现差距。将力信号纳入模仿学习（通过DP-R3M）实现新颖接触密集场景中的高成功率。

Result: 用户研究表明：力反馈将书本翻页任务的成功率从48%提升到78%，完成时间减少25%；指尖校准显著提高了薄物体抓取成功率，优于商业手套；在自适应页面翻转和力感知交接等新颖接触密集场景中实现了高成功率。

Conclusion: Glovity系统通过集成力反馈和触觉反馈，显著提升了接触密集任务的性能，在遥操作和模仿学习中表现出色。所有硬件设计和软件将开源发布。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [21] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: Placeit!是一个基于进化计算的框架，用于自动生成刚性物体的有效放置位置，支持从桌面放置到堆叠和插入等多种任务，在真实世界部署中达到90%的成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人研究在基础技能如物体放置方面仍面临挑战，主要瓶颈是获取大规模高质量数据的过程繁琐且劳动密集。受Graspit!使用仿真自动生成灵巧抓取姿态的启发，开发自动生成有效放置位置的解决方案。

Method: 采用进化计算框架，利用质量-多样性优化方法生成刚性物体的有效放置位置，支持多种放置任务场景。

Result: 实验表明，Placeit!在所有场景下都显著优于现有方法，能够生成更多样化的有效姿态。基于该框架的抓取-放置管道在120次真实世界部署中达到90%的成功率。

Conclusion: Placeit!成为开放环境抓取-放置任务的有力工具，也是生成训练基于仿真的机器人基础模型所需数据的宝贵引擎。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [22] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 本文介绍了Surrealist框架在工业四足机器人ANYmal上的应用，通过基于搜索的算法自动生成障碍规避测试场景，发现手动测试遗漏的故障，并在6个月的工业评估中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统测试方法难以覆盖动态环境中机器人导航的全部操作要求，需要自动化测试生成框架来提高测试覆盖率和发现关键故障。

Method: 采用基于搜索的算法自动生成具有挑战性的障碍规避场景，将原本用于无人机的Surrealist框架应用于ANYmal四足机器人工业检测任务。

Result: 在试点阶段，生成的测试套件发现了一个实验算法的关键弱点（成功率40.3%），并证明了另一个算法的优越鲁棒性（成功率71.2%）。在6个月工业评估中测试了5个专有算法，正式调查确认了该框架的价值。

Conclusion: Surrealist框架能够增强开发过程、发现关键故障、提供客观基准，并加强整体验证流程，在工业机器人导航测试中具有重要价值。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [23] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: FOGMACHINE是一个开源框架，将动态场景图与离散事件模拟相结合，用于在不确定环境中建模对象动态、智能体观察和交互，支持不确定性传播、有限感知规划和多智能体行为研究。


<details>
  <summary>Details</summary>
Motivation: 当前动态场景图方法难以捕捉随机动态、部分可观测性和多智能体活动，而这些对于具身AI在不确定性和延迟感知下行动至关重要。

Method: 融合动态场景图与离散事件模拟，建模对象动态、智能体观察和交互，支持大规模仿真。

Result: 在城市场景实验中展示了真实的时间和空间模式，同时揭示了在稀疏观察下信念估计的挑战。

Conclusion: 通过结合结构化表示和高效模拟，FOGMACHINE为复杂不确定环境中的基准测试、模型训练和具身AI发展建立了有效工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [24] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 开发基于Transformer的模仿学习框架，用于软体机器人导丝在血管内导航，在动脉瘤定位任务中达到83%的成功率


<details>
  <summary>Details</summary>
Motivation: 在血管内手术中，机器人导丝导航面临建模和控制挑战，自动化导航可提高精度和安全性。模仿学习在其他外科领域已显示良好效果

Method: 采用基于Transformer的模仿学习框架，包含目标条件、相对动作输出和自动对比剂注射，在36种不同分叉几何结构上训练，共647个演示

Result: 在未见过的血管几何结构上，模型能以83%的成功率自主导航机器人尖端到达动脉瘤位置，优于多个基线方法

Conclusion: 该框架能够实现可泛化的软体机器人导丝导航，为血管内手术的自动化提供了有效解决方案

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [25] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文介绍了Husky v.2多模态地面-空中机器人，通过结构复用实现动态四足行走和飞行能力


<details>
  <summary>Details</summary>
Motivation: 解决多模态机器人在不同操作模式下的冲突需求整合挑战

Method: 采用姿态操纵和推力矢量技术，通过结构复用将腿部结构重新用于动态四足行走和飞行

Result: 成功实现了动态四足行走和悬停功能

Conclusion: Husky v.2机器人通过结构复用有效解决了多模态机器人的设计挑战

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [26] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: AIMAPP是一个基于主动推理的生物启发式自主导航框架，统一了建图、定位和决策，能够在未知环境中在线构建稀疏拓扑地图，平衡目标导向和探索行为。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在未知环境中同时进行探索、定位和规划的问题，无需依赖预定义地图或大量训练，提供生物启发的模块化解决方案。

Method: 使用主动推理框架，结合海马体导航机制，采用拓扑推理、位置细胞编码和情景记忆，在线构建和更新稀疏拓扑地图，通过最小化期望自由能量来规划动作。

Result: 开发了ROS兼容的导航系统，在各种大规模真实和模拟环境中表现出鲁棒性能，能够适应模糊观测、环境变化和传感器噪声。

Conclusion: AIMAPP提供了一个生物启发的、模块化的解决方案，能够在非结构化环境中实现可扩展的自监督导航，无需任何预训练。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>
