{"id": "2510.09543", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09543", "abs": "https://arxiv.org/abs/2510.09543", "authors": ["Chenghao Wang", "Arjun Viswanathan", "Eric Sihite", "Alireza Ramezani"], "title": "Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards", "comment": null, "summary": "Animals achieve energy-efficient locomotion by their implicit passive\ndynamics, a marvel that has captivated roboticists for decades.Recently,\nmethods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning\n(RL) shows promising progress to replicate Animals' naturalistic motion.\nHowever, such imitation learning approaches predominantly capture explicit\nkinematic patterns, so-called gaits, while overlooking the implicit passive\ndynamics. This work bridges this gap by incorporating a reward term guided by\nImpact Mitigation Factor (IMF), a physics-informed metric that quantifies a\nrobot's ability to passively mitigate impacts. By integrating IMF with AMP, our\napproach enables RL policies to learn both explicit motion trajectories from\nanimal reference motion and the implicit passive dynamic. We demonstrate energy\nefficiency improvements of up to 32%, as measured by the Cost of Transport\n(CoT), across both AMP and handcrafted reward structure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u51b2\u51fb\u7f13\u89e3\u56e0\u5b50(IMF)\u548c\u5bf9\u6297\u8fd0\u52a8\u5148\u9a8c(AMP)\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u52a8\u7269\u7684\u663e\u6027\u8fd0\u52a8\u8f68\u8ff9\u548c\u9690\u6027\u88ab\u52a8\u52a8\u529b\u5b66\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe32%\u7684\u80fd\u6e90\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u52a8\u7269\u901a\u8fc7\u5176\u9690\u542b\u7684\u88ab\u52a8\u52a8\u529b\u5b66\u5b9e\u73b0\u8282\u80fd\u8fd0\u52a8\uff0c\u4f46\u73b0\u6709\u7684\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u6355\u6349\u663e\u6027\u6b65\u6001\u6a21\u5f0f\uff0c\u800c\u5ffd\u7565\u4e86\u9690\u6027\u88ab\u52a8\u52a8\u529b\u5b66\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u51b2\u51fb\u7f13\u89e3\u56e0\u5b50(IMF)\u8fd9\u4e00\u57fa\u4e8e\u7269\u7406\u7684\u6307\u6807\u6765\u91cf\u5316\u673a\u5668\u4eba\u88ab\u52a8\u7f13\u89e3\u51b2\u51fb\u7684\u80fd\u529b\uff0c\u5e76\u5c06\u5176\u4e0e\u5bf9\u6297\u8fd0\u52a8\u5148\u9a8c(AMP)\u548c\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u3002", "result": "\u5728AMP\u548c\u624b\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\u7ed3\u6784\u4e2d\uff0c\u80fd\u91cf\u6548\u7387\uff08\u901a\u8fc7\u8fd0\u8f93\u6210\u672cCoT\u8861\u91cf\uff09\u63d0\u9ad8\u4e86\u9ad8\u8fbe32%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u663e\u6027\u8fd0\u52a8\u8f68\u8ff9\u5b66\u4e60\u548c\u9690\u6027\u88ab\u52a8\u52a8\u529b\u5b66\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u7684\u80fd\u6e90\u6548\u7387\u3002"}}
