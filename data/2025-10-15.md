<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Translating Milli/Microrobots with A Value-Centered Readiness Framework](https://arxiv.org/abs/2510.12090)
*Hakan Ceylan,Edoardo Sinibaldi,Sanjay Misra,Pankaj J. Pasricha,Dietmar W. Hutmacher*

Main category: cs.RO

TL;DR: 本文回顾了无缆移动毫米/微米机器人在介入医学中的应用潜力，分析了从实验室演示到临床整合的转化障碍，并提出了技术准备度框架来加速转化。


<details>
  <summary>Details</summary>
Motivation: 尽管毫米/微米机器人在过去二十年取得了显著技术进展，但大多数仍局限于实验室概念验证，缺乏实际应用可行性。需要弥合技术创新与现实应用之间的差距。

Method: 引入战略性毫米/微米机器人技术准备度框架（mTRL），通过明确定义的里程碑和逐步活动，将系统开发从初始概念化映射到临床采用。

Result: mTRL模型提供了技术成熟度的结构化衡量标准、跨学科合作的共同语言，以及加速转化发展的可操作指导。

Conclusion: 该领域的长期影响和可持续性取决于开发与未满足医疗需求的契合、确保应用可行性，以及与现有临床工作流程的无缝整合，这些是实现有意义的患者结果的基本支柱。

Abstract: Untethered mobile milli/microrobots hold transformative potential for
interventional medicine by enabling more precise and entirely non-invasive
diagnosis and therapy. Realizing this promise requires bridging the gap between
groundbreaking laboratory demonstrations and successful clinical integration.
Despite remarkable technical progress over the past two decades, most
millirobots and microrobots remain confined to laboratory proof-of-concept
demonstrations, with limited real-world feasibility. In this Review, we
identify key factors that slow translation from bench to bedside, focusing on
the disconnect between technical innovation and real-world application. We
argue that the long-term impact and sustainability of the field depend on
aligning development with unmet medical needs, ensuring applied feasibility,
and integrating seamlessly into existing clinical workflows, which are
essential pillars for delivering meaningful patient outcomes. To support this
shift, we introduce a strategic milli/microrobot Technology Readiness Level
framework (mTRL), which maps system development from initial conceptualization
to clinical adoption through clearly defined milestones and their associated
stepwise activities. The mTRL model provides a structured gauge of
technological maturity, a common language for cross-disciplinary collaboration
and actionable guidance to accelerate translational development toward new,
safer and more efficient interventions.

</details>


### [2] [Gaussian Semantic Field for One-shot LiDAR Global Localization](https://arxiv.org/abs/2510.12101)
*Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种基于轻量级三层场景图的单次LiDAR全局定位算法，通过高斯过程学习语义分布的连续函数来缓解地标重复性问题，实现语义消歧能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于地标语义注册的方法在地标重复时容易产生误导，需要更细粒度的地理语义信息来改善对应关系建立。

Method: 使用高斯过程学习语义分布的连续函数，构建包含对象层、连续函数层和度量语义层的三层3D场景图，作为轻量级单次定位后端。

Result: 在公开数据集上的广泛实验验证了该方法相比当前最先进方法的优越性能。

Conclusion: 提出的Outram-GSF全局定位管道通过连续语义函数建模实现了更好的语义消歧和定位性能。

Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic
disambiguation ability based on a lightweight tri-layered scene graph. While
landmark semantic registration-based methods have shown promising performance
improvements in global localization compared with geometric-only methods,
landmarks can be repetitive and misleading for correspondence establishment. We
propose to mitigate this problem by modeling semantic distributions with
continuous functions learned from a population of Gaussian processes. Compared
with discrete semantic labels, the continuous functions capture finer-grained
geo-semantic information and also provide more detailed metric information for
correspondence establishment. We insert this continuous function as the middle
layer between the object layer and the metric-semantic layer, forming a
tri-layered 3D scene graph, serving as a light-weight yet performant backend
for one-shot localization. We term our global localization pipeline Outram-GSF
(Gaussian semantic field) and conduct a wide range of experiments on publicly
available data sets, validating the superior performance against the current
state-of-the-art.

</details>


### [3] [Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair](https://arxiv.org/abs/2510.12169)
*Akshay Naik,William R. Norris,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.RO

TL;DR: 提出了一种用于越野自动驾驶车辆的实时路径规划框架，结合了地形成本和车辆动力学约束，支持在软土和斜坡等非结构化环境中的可靠导航。


<details>
  <summary>Details</summary>
Motivation: 越野自动驾驶车辆需要在实时规划中同时考虑曲率可行的路径、空间变化的土壤强度和斜坡危险，以在非结构化环境中实现可靠导航。

Method: 开发了连续状态-成本度量，结合Bekker压力-沉陷模型和基于高程的斜坡惩罚；在格网上评估该度量，使用精确的转向原语；采用Vehicle-Dynamics RRT*进行全局探索，Vehicle-Dynamics D* Lite进行局部修复。

Result: 硬件试验表明，该框架能够在软土和斜坡过渡中实现实时导航，支持非结构化环境中的可靠自主性。

Conclusion: 通过将地形-车辆模型与规划器分离，该框架为可变形地形中的确定性、基于采样或学习驱动的规划提供了可重用的基础。

Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.

</details>


### [4] [Controllable Collision Scenario Generation via Collision Pattern Prediction](https://arxiv.org/abs/2510.12206)
*Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 提出可控碰撞场景生成任务，开发COLLIDE数据集和框架，能够按指定碰撞类型和时间生成碰撞场景，用于评估和提升自动驾驶车辆安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆安全性评估需要多样化的安全关键场景，特别是碰撞场景，但在现实中收集既危险又罕见。仿真生成碰撞场景是可行方案，但控制碰撞类型和时间等属性仍具挑战。

Method: 构建COLLIDE大规模碰撞场景数据集，将真实驾驶日志转换为多样化碰撞；提出预测碰撞模式的框架，该模式是紧凑可解释的表示，捕获碰撞时自车和对抗车辆的空间配置；然后展开完整对抗轨迹。

Result: 实验表明该方法在碰撞率和可控性方面优于强基线；生成的场景能持续诱导更高的规划器失败率，揭示现有规划器的局限性；这些场景可用于微调规划器，提升鲁棒性。

Conclusion: 提出的可控碰撞场景生成方法能有效生成指定碰撞类型和时间的场景，有助于评估和改进自动驾驶车辆在不同碰撞场景中的安全性，促进更安全的自动驾驶部署。

Abstract: Evaluating the safety of autonomous vehicles (AVs) requires diverse,
safety-critical scenarios, with collisions being especially important yet rare
and unsafe to collect in the real world. Therefore, the community has been
focusing on generating safety-critical scenarios in simulation. However,
controlling attributes such as collision type and time-to-accident (TTA)
remains challenging. We introduce a new task called controllable collision
scenario generation, where the goal is to produce trajectories that realize a
user-specified collision type and TTA, to investigate the feasibility of
automatically generating desired collision scenarios. To support this task, we
present COLLIDE, a large-scale collision scenario dataset constructed by
transforming real-world driving logs into diverse collisions, balanced across
five representative collision types and different TTA intervals. We propose a
framework that predicts Collision Pattern, a compact and interpretable
representation that captures the spatial configuration of the ego and the
adversarial vehicles at impact, before rolling out full adversarial
trajectories. Experiments show that our approach outperforms strong baselines
in both collision rate and controllability. Furthermore, generated scenarios
consistently induce higher planner failure rates, revealing limitations of
existing planners. We demonstrate that these scenarios fine-tune planners for
robustness improvements, contributing to safer AV deployment in different
collision scenarios.

</details>


### [5] [Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications](https://arxiv.org/abs/2510.12215)
*Chanwoo Kim,Jihwan Yoon,Hyeonseong Kim,Taemoon Jeong,Changwoo Yoo,Seungbeen Lee,Soohwan Byeon,Hoon Chung,Matthew Pan,Jean Oh,Kyungjae Lee,Sungjoon Choi*

Main category: cs.RO

TL;DR: 提出了一种结合数据驱动奖励和基于规则目标的移动机器人导航框架，通过密度奖励学习和规则约束实现安全与自适应的平衡，使用采样前瞻控制器生成监督动作并蒸馏为紧凑的学生策略。


<details>
  <summary>Details</summary>
Motivation: 在动态人类环境中，移动机器人导航需要平衡对多样化行为的适应性和对安全约束的遵守。假设将数据驱动奖励与基于规则的目标相结合，可以实现更好的适应性与安全性平衡。

Method: 开发了一个框架，从正负演示中学习基于密度的奖励，并用基于规则的障碍物避让和目标到达目标进行增强。使用采样前瞻控制器生成安全且自适应的监督动作，然后将其蒸馏为适合实时操作的紧凑学生策略，并提供不确定性估计。

Result: 在合成和电梯共乘模拟实验中，相比基线方法在成功率和时间效率方面均取得一致增益。与人类参与者的真实世界演示证实了部署的实用性。

Conclusion: 该框架成功实现了在动态人类环境中平衡适应性和安全性的移动机器人导航，通过数据驱动奖励与规则约束的结合，在模拟和真实环境中均表现出优越性能。

Abstract: Mobile robot navigation in dynamic human environments requires policies that
balance adaptability to diverse behaviors with compliance to safety
constraints. We hypothesize that integrating data-driven rewards with
rule-based objectives enables navigation policies to achieve a more effective
balance of adaptability and safety. To this end, we develop a framework that
learns a density-based reward from positive and negative demonstrations and
augments it with rule-based objectives for obstacle avoidance and goal
reaching. A sampling-based lookahead controller produces supervisory actions
that are both safe and adaptive, which are subsequently distilled into a
compact student policy suitable for real-time operation with uncertainty
estimates. Experiments in synthetic and elevator co-boarding simulations show
consistent gains in success rate and time efficiency over baselines, and
real-world demonstrations with human participants confirm the practicality of
deployment. A video illustrating this work can be found on our project page
https://chanwookim971024.github.io/PioneeR/.

</details>


### [6] [Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](https://arxiv.org/abs/2510.12276)
*Fuhao Li,Wenxuan Song,Han Zhao,Jingbo Wang,Pengxiang Ding,Donglin Wang,Long Zeng,Haoang Li*

Main category: cs.RO

TL;DR: 提出了一种名为Spatial Forcing (SF)的对齐策略，通过将视觉语言动作模型的中间视觉嵌入与预训练3D基础模型的几何表示对齐，隐式地增强模型的空间理解能力，无需依赖显式3D输入或深度估计器。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型大多基于仅使用2D数据预训练的视觉语言模型，缺乏准确的空间感知能力，限制了在3D物理世界中的操作能力。现有解决方案要么依赖有噪声的3D传感器输入，要么受限于深度估计器的性能。

Method: SF策略在中间层将VLA模型的视觉嵌入与预训练3D基础模型的几何表示进行对齐，引导VLA模型编码更丰富的空间表示，从而提升动作精度。

Result: 在仿真和真实环境中的广泛实验表明，SF实现了最先进的性能，超越了基于2D和3D的VLA模型。SF进一步将训练速度提升了最高3.8倍，并在多样化的机器人任务中提高了数据效率。

Conclusion: SF是一种简单而有效的对齐策略，能够隐式地增强VLA模型的空间理解能力，无需显式3D输入，在提升性能的同时显著加速训练过程。

Abstract: Vision-language-action (VLA) models have recently shown strong potential in
enabling robots to follow language instructions and execute precise actions.
However, most VLAs are built upon vision-language models pretrained solely on
2D data, which lack accurate spatial awareness and hinder their ability to
operate in the 3D physical world. Existing solutions attempt to incorporate
explicit 3D sensor inputs such as depth maps or point clouds, but these
approaches face challenges due to sensor noise, hardware heterogeneity, and
incomplete depth coverage in existing datasets. Alternative methods that
estimate 3D cues from 2D images also suffer from the limited performance of
depth estimators.We propose Spatial Forcing (SF), a simple yet effective
alignment strategy that implicitly forces VLA models to develop spatial
comprehension capabilities without relying on explicit 3D inputs or depth
estimators. SF aligns intermediate visual embeddings of VLAs with geometric
representations produced by pretrained 3D foundation models. By enforcing
alignment at intermediate layers, SF guides VLAs to encode richer spatial
representations that enhance action precision.Extensive experiments in
simulation and real-world environments demonstrate that SF achieves
state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further
accelerates training by up to 3.8x and improves data efficiency across diverse
robotic tasks. Project page is at https://spatial-forcing.github.io/

</details>


### [7] [Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics](https://arxiv.org/abs/2510.12332)
*Mohammadreza Kasaei,Mostafa Ghobadi,Mohsen Khadem*

Main category: cs.RO

TL;DR: 提出了一种用于肌腱驱动连续机器人的形状感知全身控制框架，应用于腔内手术导航。该框架结合物理信息骨架模型和增强神经ODE的残差学习，实现精确形状估计和高效雅可比计算，通过MPPI控制器优化尖端跟踪、骨架顺应性和障碍物避让。


<details>
  <summary>Details</summary>
Motivation: 传统仅控制尖端的方法在腔内手术（如支气管镜检查）中容易导致壁接触、组织损伤或无法到达远端目标，需要更精确安全的导航方法。

Method: 结合物理信息骨架模型与增强神经ODE的残差学习进行形状估计，使用基于采样的MPPI控制器联合优化尖端跟踪、骨架顺应性和障碍物避让，任务管理器支持实时调整目标。

Result: 仿真研究显示毫米级精度，包括轨迹跟踪、动态障碍物避让和形状约束到达。在支气管镜模型上的真实机器人实验显示改进的管腔跟随精度、减少的壁接触和增强的适应性。

Conclusion: 该框架有潜力提高微创腔内手术的安全性、可靠性和操作效率，对其他受限和安全关键环境具有广泛适用性。

Abstract: This paper presents a shape-aware whole-body control framework for
tendon-driven continuum robots with direct application to endoluminal surgical
navigation. Endoluminal procedures, such as bronchoscopy, demand precise and
safe navigation through tortuous, patient-specific anatomy where conventional
tip-only control often leads to wall contact, tissue trauma, or failure to
reach distal targets. To address these challenges, our approach combines a
physics-informed backbone model with residual learning through an Augmented
Neural ODE, enabling accurate shape estimation and efficient Jacobian
computation. A sampling-based Model Predictive Path Integral (MPPI) controller
leverages this representation to jointly optimize tip tracking, backbone
conformance, and obstacle avoidance under actuation constraints. A task manager
further enhances adaptability by allowing real-time adjustment of objectives,
such as wall clearance or direct advancement, during tele-operation. Extensive
simulation studies demonstrate millimeter-level accuracy across diverse
scenarios, including trajectory tracking, dynamic obstacle avoidance, and
shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom
validate the framework, showing improved lumen-following accuracy, reduced wall
contacts, and enhanced adaptability compared to joystick-only navigation and
existing baselines. These results highlight the potential of the proposed
framework to increase safety, reliability, and operator efficiency in minimally
invasive endoluminal surgery, with broader applicability to other confined and
safety-critical environments.

</details>


### [8] [Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task](https://arxiv.org/abs/2510.12340)
*Nicky Mol,Luka Peternel,Alessandro Ianniello,Denis Zatyagov,Auke Nachenius,Stephan Balvert,J. Micah Prendergast,Sara Muscolo,Olger Siebinga,Eva Verhoef,Deborah Forster,David A. Abbink*

Main category: cs.RO

TL;DR: 本文主张并展示在工作场所机器人应用中采用跨学科方法，强调学术研究与实践经验、体验知识的整合，以提升工人福祉和工作吸引力。


<details>
  <summary>Details</summary>
Motivation: 工业机器人应用增长需要应对劳动力短缺、人口老龄化和生产需求增加等社会挑战，需要更全面的方法来确保技术应用符合人类价值。

Method: 采用跨学科方法，整合学术研究、实践专业知识和体验知识，在飞机发动机维修和维护操作中探索协作机器人的潜力。

Result: 正在进行多方面的努力来研究协作机器人在特定工业环境中的应用可能性。

Conclusion: 跨学科方法对于在工作场所成功部署机器人技术至关重要，能够平衡技术效率与人类福祉价值。

Abstract: The use of robots in industrial settings continues to grow, driven by the
need to address complex societal challenges such as labor shortages, aging
populations, and ever-increasing production demands. In this abstract, we
advocate for (and demonstrate) a transdisciplinary approach when considering
robotics in the workplace. Transdisciplinarity emphasizes the integration of
academic research with pragmatic expertise and embodied experiential knowledge,
that prioritize values such as worker wellbeing and job attractiveness. In the
following, we describe an ongoing multi-pronged effort to explore the potential
of collaborative robots in the context of airplane engine repair and
maintenance operations.

</details>


### [9] [PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing](https://arxiv.org/abs/2510.12346)
*Bingquan Li,Ning Wang,Tianwei Zhang,Zhicheng He,Yucong Wu*

Main category: cs.RO

TL;DR: 提出PolyMap框架，基于多传感器融合构建实时多边形楼梯平面语义地图，用于人形机器人爬楼梯的感知驱动运动规划。


<details>
  <summary>Details</summary>
Motivation: 模拟人类行走，使机器人能够在未知空间中准确踩踏位置，特别是在爬楼梯场景中。

Method: 使用多传感器融合（LiDAR、RGB-D相机和IMU）进行平面分割和视觉里程计，构建实时多边形楼梯平面语义地图，并基于这些多边形平面段进行脚步规划。

Result: 在NVIDIA Orin上部署，实现20-30Hz全身运动规划输出，室内外真实场景实验表明方法高效且鲁棒。

Conclusion: PolyMap框架为人形机器人爬楼梯提供了有效的感知驱动运动规划解决方案。

Abstract: Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.

</details>


### [10] [Controlling Intent Expressiveness in Robot Motion with Diffusion Models](https://arxiv.org/abs/2510.12370)
*Wenli Shi,Clemence Grislain,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 提出了一种新颖的运动生成框架，能够在从高度可读性到高度模糊性的全谱系范围内实现可控的可读性。该方法基于信息势场建模，并使用两阶段扩散框架生成指定可读性水平的路径和可执行动作。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹生成方法通常优先考虑效率，但往往无法让人类清晰理解机器人的意图。现有的可读性运动方法通常只产生单一的"最可读"轨迹，忽视了在不同情境下调节意图表达的需求。

Method: 基于信息势场建模为轨迹分配连续可读性评分，并构建两阶段扩散框架：首先生成指定可读性水平的路径，然后将其转换为可执行的机器人动作。

Result: 在2D和3D到达任务中的实验表明，该方法能够产生具有不同可读性程度的多样化且可控的运动，同时达到与最先进方法相当的性能。

Conclusion: 该框架成功实现了机器人运动可读性的连续可控调节，为不同交互场景下的意图表达提供了灵活解决方案。

Abstract: Legibility of robot motion is critical in human-robot interaction, as it
allows humans to quickly infer a robot's intended goal. Although traditional
trajectory generation methods typically prioritize efficiency, they often fail
to make the robot's intentions clear to humans. Meanwhile, existing approaches
to legible motion usually produce only a single "most legible" trajectory,
overlooking the need to modulate intent expressiveness in different contexts.
In this work, we propose a novel motion generation framework that enables
controllable legibility across the full spectrum, from highly legible to highly
ambiguous motions. We introduce a modeling approach based on an Information
Potential Field to assign continuous legibility scores to trajectories, and
build upon it with a two-stage diffusion framework that first generates paths
at specified legibility levels and then translates them into executable robot
actions. Experiments in both 2D and 3D reaching tasks demonstrate that our
approach produces diverse and controllable motions with varying degrees of
legibility, while achieving performance comparable to SOTA. Code and project
page: https://legibility-modulator.github.io.

</details>


### [11] [Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking](https://arxiv.org/abs/2510.12392)
*Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park*

Main category: cs.RO

TL;DR: 本文提出了两种新技术（自引导和自适应分块）来增强扩散策略的一致性和反应性，显著提高了生成行为克隆在多任务机器人学习中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成行为克隆方法使用开环控制的扩散策略，虽然成功率高且泛化能力强，但其固有的随机性可能导致错误动作采样和意外任务失败，且在噪声或动态环境中存在延迟响应问题。

Method: 提出了两种新技术：1）自引导技术，通过利用过去观察并隐式促进未来感知行为来提高动作保真度；2）自适应分块技术，当反应性收益超过时间一致性需求时，选择性更新动作序列。

Result: 大量实验表明，该方法在广泛的模拟和真实世界机器人操作任务中显著提高了生成行为克隆的性能。

Conclusion: 通过自引导和自适应分块技术，成功解决了扩散策略在生成行为克隆中的一致性和反应性问题，为多任务机器人学习提供了更可靠的解决方案。

Abstract: Generative Behavior Cloning (GBC) is a simple yet effective framework for
robot learning, particularly in multi-task settings. Recent GBC methods often
employ diffusion policies with open-loop (OL) control, where actions are
generated via a diffusion process and executed in multi-step chunks without
replanning. While this approach has demonstrated strong success rates and
generalization, its inherent stochasticity can result in erroneous action
sampling, occasionally leading to unexpected task failures. Moreover, OL
control suffers from delayed responses, which can degrade performance in noisy
or dynamic environments. To address these limitations, we propose two novel
techniques to enhance the consistency and reactivity of diffusion policies: (1)
self-guidance, which improves action fidelity by leveraging past observations
and implicitly promoting future-aware behavior; and (2) adaptive chunking,
which selectively updates action sequences when the benefits of reactivity
outweigh the need for temporal consistency. Extensive experiments show that our
approach substantially improves GBC performance across a wide range of
simulated and real-world robotic manipulation tasks. Our code is available at
https://github.com/junhyukso/SGAC

</details>


### [12] [Robot Learning: A Tutorial](https://arxiv.org/abs/2510.12403)
*Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi*

Main category: cs.RO

TL;DR: 本教程概述了现代机器人学习的发展历程，从强化学习和行为克隆的基础原理到能够跨任务和机器人平台操作的通用语言条件模型。


<details>
  <summary>Details</summary>
Motivation: 机器人学习正处于转折点，机器学习快速发展和大规模机器人数据的可用性推动了从传统基于模型方法向数据驱动学习范式的转变，这为自主系统解锁了前所未有的能力。

Method: 教程从强化学习和行为克隆的基础原理出发，逐步介绍到通用语言条件模型，使用$	exttt{lerobot}$实现即用示例。

Result: 为研究人员和从业者提供了概念理解和实践工具，使他们能够为机器人学习的发展做出贡献。

Conclusion: 本教程旨在指导读者掌握现代机器人学习的关键概念和实用工具，推动该领域的发展。

Abstract: Robot learning is at an inflection point, driven by rapid advancements in
machine learning and the growing availability of large-scale robotics data.
This shift from classical, model-based methods to data-driven, learning-based
paradigms is unlocking unprecedented capabilities in autonomous systems. This
tutorial navigates the landscape of modern robot learning, charting a course
from the foundational principles of Reinforcement Learning and Behavioral
Cloning to generalist, language-conditioned models capable of operating across
diverse tasks and even robot embodiments. This work is intended as a guide for
researchers and practitioners, and our goal is to equip the reader with the
conceptual understanding and practical tools necessary to contribute to
developments in robot learning, with ready-to-use examples implemented in
$\texttt{lerobot}$.

</details>


### [13] [M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing](https://arxiv.org/abs/2510.12419)
*Shunnosuke Yoshimura,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种名为M3D-skin的触觉传感器，利用多材料FDM 3D打印机的填充图案作为传感原理，通过导电和非导电柔性材料创建分层结构，在压力下变形导致电阻变化来获取触觉信息。


<details>
  <summary>Details</summary>
Motivation: 如果触觉传感器能够更容易地制造和集成，其应用范围将进一步扩大。

Method: 利用多材料FDM 3D打印技术，使用导电和非导电柔性材料创建具有特定填充图案的分层结构，通过结构变形引起的电阻变化来检测触觉信息。

Result: 测量了分层结构修改对传感器特性的影响，展示了多瓦片传感器的制造和使用，实现了足底运动模式测量、与机器人手的集成以及基于触觉的机器人操作。

Conclusion: 通过实验验证了所提出的触觉传感器的有效性。

Abstract: Tactile sensors have a wide range of applications, from utilization in
robotic grippers to human motion measurement. If tactile sensors could be
fabricated and integrated more easily, their applicability would further
expand. In this study, we propose a tactile sensor-M3D-skin-that can be easily
fabricated with high versatility by leveraging the infill patterns of a
multi-material fused deposition modeling (FDM) 3D printer as the sensing
principle. This method employs conductive and non-conductive flexible filaments
to create a hierarchical structure with a specific infill pattern. The flexible
hierarchical structure deforms under pressure, leading to a change in
electrical resistance, enabling the acquisition of tactile information. We
measure the changes in characteristics of the proposed tactile sensor caused by
modifications to the hierarchical structure. Additionally, we demonstrate the
fabrication and use of a multi-tile sensor. Furthermore, as applications, we
implement motion pattern measurement on the sole of a foot, integration with a
robotic hand, and tactile-based robotic operations. Through these experiments,
we validate the effectiveness of the proposed tactile sensor.

</details>


### [14] [A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation](https://arxiv.org/abs/2510.12477)
*Gaoyuan Liu,Joris de Winter,Kelly Merckaert,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 提出一种混合强化学习规划框架，结合交互式运动规划器和RL任务规划器，解决人机协作中安全与效率的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在人机协作环境中，安全机制通常会影响任务效率，因为人为干预会导致机器人备份运动和目标失败。频繁的运动重规划会增加计算负载和失败几率。

Method: 使用混合RL规划框架，包含交互式运动规划器和RL任务规划器。RL任务规划器基于运动规划器的反馈选择统计上安全高效的任务序列，运动规划器通过检测人体手臂运动并在路径无效时部署新路径来保持任务执行过程无碰撞。

Result: 在仿真和真实世界中对协作机器人进行验证，与硬编码任务运动规划方法比较。结果显示该框架能够：1）在关节和任务层面响应不确定的人体运动；2）减少重复失败目标命令的次数；3）减少重规划请求的总数。

Conclusion: 提出的混合RL规划框架能够有效平衡人机协作中的安全性和效率，通过学习避免危险任务并确保所选任务的安全性。

Abstract: In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.

</details>


### [15] [Fast Visuomotor Policy for Robotic Manipulation](https://arxiv.org/abs/2510.12483)
*Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang*

Main category: cs.RO

TL;DR: Energy Policy是一个用于机器人操作的高效策略框架，能够在单次前向传播中预测多模态动作，实现高速高精度操作，同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 针对高频机器人任务和资源受限系统，需要设计一个既快速又有效的策略框架，能够原生支持多模态动作预测。

Method: 框架基于两个核心组件：采用能量分数作为学习目标以促进多模态动作建模，并引入能量MLP来实现该目标同时保持架构简单高效。

Result: 在模拟环境和真实机器人任务中的实验表明，Energy Policy在性能上匹配或超越最先进的操作方法，同时显著减少计算开销。在MimicGen基准测试中，以更快的推理速度实现了更优性能。

Conclusion: Energy Policy是一个高效且有效的机器人操作策略框架，能够在保持高性能的同时显著降低计算需求，适用于高频和资源受限的机器人应用场景。

Abstract: We present a fast and effective policy framework for robotic manipulation,
named Energy Policy, designed for high-frequency robotic tasks and
resource-constrained systems. Unlike existing robotic policies, Energy Policy
natively predicts multimodal actions in a single forward pass, enabling
high-precision manipulation at high speed. The framework is built upon two core
components. First, we adopt the energy score as the learning objective to
facilitate multimodal action modeling. Second, we introduce an energy MLP to
implement the proposed objective while keeping the architecture simple and
efficient. We conduct comprehensive experiments in both simulated environments
and real-world robotic tasks to evaluate the effectiveness of Energy Policy.
The results show that Energy Policy matches or surpasses the performance of
state-of-the-art manipulation methods while significantly reducing
computational overhead. Notably, on the MimicGen benchmark, Energy Policy
achieves superior performance with at a faster inference compared to existing
approaches.

</details>


### [16] [Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge](https://arxiv.org/abs/2510.12509)
*Gaoyuan Liu,Bas Boom,Naftali Slob,Yuri Durodié,Ann Nowé,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本文提出了一种用于果园修剪的机器人行为规划方法，解决了在复杂碰撞环境中多级规划问题，通过整合感知、建模和整体规划来提升修剪性能。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究主要关注感知挑战，但修剪操作中的复杂操纵问题常被忽视，包括在关节空间和笛卡尔空间中的规划与控制，以引导末端执行器穿过复杂的树枝障碍。

Method: 制定高维机械臂在修剪场景中的规划问题，研究系统内在冗余性，提出整合感知、建模和整体规划的完整修剪工作流程。

Result: 实验证明更全面的规划方法能显著提升机器人操纵器性能，并在真实机器人上实现了所提出的工作流程。

Conclusion: 这项工作补充了先前关于机器人修剪的研究，并激发了修剪应用中规划问题的未来研究和发展。

Abstract: Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.

</details>


### [17] [Learning Robust Agile Flight Control with Stability Guarantees](https://arxiv.org/abs/2510.12611)
*Lukas Pries,Markus Ryll*

Main category: cs.RO

TL;DR: 提出了一种新型神经增强反馈控制器，用于高速敏捷四旋翼飞行控制，该控制器结合了现有控制范式的优势，提供通用稳定性保证，能够在高扰动环境中实现精确轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 在高速敏捷四旋翼飞行中，需要在平台操作极限下实现精确轨迹跟踪，控制器必须处理执行器约束、对扰动具有鲁棒性，并且在安全关键应用中保持计算效率。

Method: 开发了一种神经增强反馈控制器，该控制器统一了现有最先进控制范式的优势，具有非线性反馈结构，能够在仿真中快速稳定学习。

Result: 控制器能够准确跟踪高度激进的轨迹，甚至超越执行器的可行性限制，在极度扰动环境中表现出增强的鲁棒性和跟踪性能，计算效率高，支持高更新率。

Conclusion: 该控制器无需训练增强或微调即可直接部署到真实世界平台，为高速敏捷四旋翼飞行提供了具有通用稳定性保证的高效控制解决方案。

Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving
precise trajectory tracking at the platform's operational limits is paramount.
Controllers must handle actuator constraints, exhibit robustness to
disturbances, and remain computationally efficient for safety-critical
applications. In this work, we present a novel neural-augmented feedback
controller for agile flight control. The controller addresses individual
limitations of existing state-of-the-art control paradigms and unifies their
strengths. We demonstrate the controller's capabilities, including the accurate
tracking of highly aggressive trajectories that surpass the feasibility of the
actuators. Notably, the controller provides universal stability guarantees,
enhancing its robustness and tracking performance even in exceedingly
disturbance-prone settings. Its nonlinear feedback structure is highly
efficient enabling fast computation at high update rates. Moreover, the
learning process in simulation is both fast and stable, and the controller's
inherent robustness allows direct deployment to real-world platforms without
the need for training augmentations or fine-tuning.

</details>


### [18] [Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop](https://arxiv.org/abs/2510.12662)
*Oz Gitelson,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 提出了一种人机逻辑交互框架，使机器人能够可靠满足时序逻辑任务，同时与追求独立未知任务的人类有效协作。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人需要满足长期时序逻辑任务，同时最小化对人类自主性的干扰，并在人类目标冲突时仍能保证任务完成的问题。

Method: 结合最大适应性和最小可调反馈两种能力：最大适应性使机器人能够在线调整策略以利用人类行为进行协作；最小可调反馈仅在必要时请求人类合作以保证进展。

Result: 在真实世界块操作任务和Overcooked-AI基准测试中验证，该方法产生了超越现有方法的丰富涌现协作行为，同时保持强大的形式化保证。

Conclusion: 该框架成功平衡了人机协作中的适应性和干扰最小化，实现了在人类目标冲突情况下仍能保证机器人任务完成的可靠协作。

Abstract: We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.

</details>


### [19] [Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning](https://arxiv.org/abs/2510.12684)
*Alvaro Belmonte-Baeza,Miguel Cazorla,Gabriel J. García,Carlos J. Pérez-Del-Pulgar,Jorge Pomares*

Main category: cs.RO

TL;DR: 提出了一种用于月球环境中四足移动机械臂的约束强化学习框架，整合了全身运动和操作能力，同时满足碰撞避免、动态稳定性和功率效率等安全约束。


<details>
  <summary>Details</summary>
Motivation: 轮式机器人在非结构化和陡峭地形中的局限性促使采用腿式机器人，其在月球环境中具有更好的移动性和适应性。

Method: 使用约束强化学习框架，集成全身运动和操作能力，明确处理碰撞避免、动态稳定性和功率效率等关键安全约束。

Result: 实现了精确的6D任务空间末端执行器姿态跟踪，平均位置精度为4厘米，方向精度为8.1度，系统始终尊重软硬约束，并表现出针对月球重力条件优化的自适应行为。

Conclusion: 该工作有效桥接了自适应学习与关键任务安全需求，为未来月球任务的先进自主机器人探索者铺平了道路。

Abstract: Robotics plays a pivotal role in planetary science and exploration, where
autonomous and reliable systems are crucial due to the risks and challenges
inherent to space environments. The establishment of permanent lunar bases
demands robotic platforms capable of navigating and manipulating in the harsh
lunar terrain. While wheeled rovers have been the mainstay for planetary
exploration, their limitations in unstructured and steep terrains motivate the
adoption of legged robots, which offer superior mobility and adaptability. This
paper introduces a constrained reinforcement learning framework designed for
autonomous quadrupedal mobile manipulators operating in lunar environments. The
proposed framework integrates whole-body locomotion and manipulation
capabilities while explicitly addressing critical safety constraints, including
collision avoidance, dynamic stability, and power efficiency, in order to
ensure robust performance under lunar-specific conditions, such as reduced
gravity and irregular terrain. Experimental results demonstrate the framework's
effectiveness in achieving precise 6D task-space end-effector pose tracking,
achieving an average positional accuracy of 4 cm and orientation accuracy of
8.1 degrees. The system consistently respects both soft and hard constraints,
exhibiting adaptive behaviors optimized for lunar gravity conditions. This work
effectively bridges adaptive learning with essential mission-critical safety
requirements, paving the way for advanced autonomous robotic explorers for
future lunar missions.

</details>


### [20] [Reflection-Based Task Adaptation for Self-Improving VLA](https://arxiv.org/abs/2510.12710)
*Baicheng Li,Dong Wu,Zike Yan,Xinchen Liu,Zecui Zeng,Lusong Li,Hongbin Zha*

Main category: cs.RO

TL;DR: 提出Reflective Self-Adaptation框架，通过双路径架构实现VLA模型在新型任务中的快速自主适应，包含失败驱动的反思RL和成功驱动的质量引导SFT，显著提升学习效率和最终成功率。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作模型在向通用机器人发展方面取得重大进展，但在现场适应新型特定任务时仍面临效率低下的挑战，需要解决强化学习适应过程中的低效问题。

Method: 采用双路径架构：1) 失败驱动的反思RL路径，利用VLM的因果推理自动从失败分析中合成密集奖励函数；2) 成功驱动的质量引导SFT路径，通过选择性模仿高质量成功轨迹来确保策略与任务目标对齐，并采用条件课程机制辅助初始探索。

Result: 在具有挑战性的操作任务实验中，该框架相比代表性基线方法实现了更快的收敛速度和更高的最终成功率。

Conclusion: 该工作为创建能够高效可靠适应新环境的自我改进智能体提供了稳健解决方案。

Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap
towards general-purpose robots, yet efficiently adapting them to novel,
specific tasks in-situ remains a significant hurdle. While reinforcement
learning (RL) is a promising avenue for such adaptation, the process often
suffers from low efficiency, hindering rapid task mastery. We introduce
Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation
without human intervention. Our framework establishes a self-improving loop
where the agent learns from its own experience to enhance both strategy and
execution.
  The core of our framework is a dual-pathway architecture that addresses the
full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway
enables rapid learning by using the VLM's causal reasoning to automatically
synthesize a targeted, dense reward function from failure analysis. This
provides a focused learning signal that significantly accelerates policy
exploration. However, optimizing such proxy rewards introduces a potential risk
of "reward hacking," where the agent masters the reward function but fails the
actual task. To counteract this, our second pathway, Success-Driven
Quality-Guided SFT, grounds the policy in holistic success. It identifies and
selectively imitates high-quality successful trajectories, ensuring the agent
remains aligned with the ultimate task goal. This pathway is strengthened by a
conditional curriculum mechanism to aid initial exploration.
  We conduct experiments in challenging manipulation tasks. The results
demonstrate that our framework achieves faster convergence and higher final
success rates compared to representative baselines. Our work presents a robust
solution for creating self-improving agents that can efficiently and reliably
adapt to new environments.

</details>


### [21] [Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control](https://arxiv.org/abs/2510.12717)
*Se Hwan Jeon,Ho Jae Lee,Seungwoo Hong,Sangbae Kim*

Main category: cs.RO

TL;DR: 提出了一种GPU并行化的残差架构，将MPC和RL在力矩控制层面紧密集成，结合了模型控制的解释性和约束处理能力与RL的适应性。


<details>
  <summary>Details</summary>
Motivation: MPC提供可解释、可调谐的控制器但受限于模型失配和实时计算约束，RL能产生鲁棒行为但缺乏解释性且需要大量奖励工程。

Method: 开发了基于动力学全身MPC公式，在100Hz频率下并行评估数千个智能体进行RL训练，残差策略学习对MPC输出进行针对性修正。

Result: 相比独立MPC或端到端RL，该方法实现了更高的样本效率、更大的渐近奖励、更广的可跟踪速度命令范围，并能零样本适应未见步态和不平地形。

Conclusion: 模型控制先验作为强偏差，用简单奖励集引导策略朝向期望行为，结合了模型控制的可解释性和RL的适应性优势。

Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion
controllers grounded in physical models, but its robustness depends on frequent
replanning and is limited by model mismatch and real-time computational
constraints. Reinforcement Learning (RL), by contrast, can produce highly
robust behaviors through stochastic training but often lacks interpretability,
suffers from out-of-distribution failures, and requires intensive reward
engineering. This work presents a GPU-parallelized residual architecture that
tightly integrates MPC and RL by blending their outputs at the torque-control
level. We develop a kinodynamic whole-body MPC formulation evaluated across
thousands of agents in parallel at 100 Hz for RL training. The residual policy
learns to make targeted corrections to the MPC outputs, combining the
interpretability and constraint handling of model-based control with the
adaptability of RL. The model-based control prior acts as a strong bias,
initializing and guiding the policy towards desirable behavior with a simple
set of rewards. Compared to standalone MPC or end-to-end RL, our approach
achieves higher sample efficiency, converges to greater asymptotic rewards,
expands the range of trackable velocity commands, and enables zero-shot
adaptation to unseen gaits and uneven terrain.

</details>


### [22] [T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](https://arxiv.org/abs/2510.12724)
*Xin Fei,Zhixuan Xu,Huaicong Fang,Tianrui Zhang,Lin Shao*

Main category: cs.RO

TL;DR: T(R,O) Grasp是一个基于扩散模型的灵巧抓取框架，通过统一的T(R,O)图表示法高效生成准确多样的抓取姿态，在多种机器人手上实现94.83%的平均成功率，推理速度达0.21秒。


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取在机器人领域面临高维状态和动作空间的复杂性挑战，需要开发能够高效生成准确多样抓取姿态的解决方案。

Method: 提出T(R,O)图统一表示法，建模机器人手与物体间的空间变换关系并编码几何属性，结合图扩散模型和高效逆运动学求解器，支持无条件与条件抓取合成。

Result: 在多种灵巧手上实现94.83%平均成功率，推理速度0.21秒，A100 GPU上吞吐量41抓取/秒，显著优于现有基线方法，同时降低内存消耗并具备跨具身泛化能力。

Conclusion: 该方法具有高推理速度，支持闭环灵巧操作，有潜力发展为灵巧抓取的基础模型。

Abstract: Dexterous grasping remains a central challenge in robotics due to the
complexity of its high-dimensional state and action space. We introduce T(R,O)
Grasp, a diffusion-based framework that efficiently generates accurate and
diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,
a unified representation that models spatial transformations between robotic
hands and objects while encoding their geometric properties. A graph diffusion
model, coupled with an efficient inverse kinematics solver, supports both
unconditioned and conditioned grasp synthesis. Extensive experiments on a
diverse set of dexterous hands show that T(R,O) Grasp achieves average success
rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per
second on an NVIDIA A100 40GB GPU, substantially outperforming existing
baselines. In addition, our approach is robust and generalizable across
embodiments while significantly reducing memory consumption. More importantly,
the high inference speed enables closed-loop dexterous manipulation,
underscoring the potential of T(R,O) Grasp to scale into a foundation model for
dexterous grasping.

</details>


### [23] [HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](https://arxiv.org/abs/2510.12733)
*Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork*

Main category: cs.RO

TL;DR: HYPE是一个混合运动规划器，通过将学习到的多模态轨迹提案作为启发式先验集成到蒙特卡洛树搜索中，简化了成本函数设计，并在复杂城市环境中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市环境中进行安全和可解释的运动规划需要处理双向多智能体交互，而设计编码期望车辆行为的成本函数非常具有挑战性。

Method: 提出HYPE混合规划器，将学习到的提案模型生成的多模态轨迹作为启发式先验集成到蒙特卡洛树搜索细化中，并引入自我条件占用预测模型来建模双向交互。

Result: 在nuPlan和DeepUrban大规模真实世界基准测试中，HYPE有效实现了最先进的性能，特别是在安全性和适应性方面。

Conclusion: HYPE通过提案驱动的引导显著简化了细化过程中的成本函数设计，仅需最小化的基于网格的成本项，就能在复杂城市环境中实现安全和适应性强的运动规划。

Abstract: Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.

</details>
