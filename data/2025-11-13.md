<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Practical and Performant Enhancements for Maximization of Algebraic Connectivity](https://arxiv.org/abs/2511.08694)
*Leonard Jung,Alan Papalia,Kevin Doherty,Michael Everett*

Main category: cs.RO

TL;DR: 本文提出了一种改进的图稀疏化算法MAC，通过最大化代数连通性来保持估计性能，解决了现有方法在大规模长期图上计算效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 当前图估计方法在大规模长期图上扩展性差，MAC算法虽然性能优越但计算成本高且需要手动指定保持连通性的边集，限制了其在线应用。

Method: 开发了专门的代数连通性求解器（平均提速2倍）、研究MAC优化过程中的步长策略以提升收敛速度和解决方案质量、提出自动保证图连通性的方案。

Result: 这些改进使MAC算法更具可扩展性、可靠性和实时性，适用于实时估计应用。

Conclusion: 通过计算效率优化和自动化连通性保证，显著提升了MAC算法的实用性，使其更适合在线图估计任务。

Abstract: Long-term state estimation over graphs remains challenging as current graph estimation methods scale poorly on large, long-term graphs. To address this, our work advances a current state-of-the-art graph sparsification algorithm, maximizing algebraic connectivity (MAC). MAC is a sparsification method that preserves estimation performance by maximizing the algebraic connectivity, a spectral graph property that is directly connected to the estimation error. Unfortunately, MAC remains computationally prohibitive for online use and requires users to manually pre-specify a connectivity-preserving edge set. Our contributions close these gaps along three complementary fronts: we develop a specialized solver for algebraic connectivity that yields an average 2x runtime speedup; we investigate advanced step size strategies for MAC's optimization procedure to enhance both convergence speed and solution quality; and we propose automatic schemes that guarantee graph connectivity without requiring manual specification of edges. Together, these contributions make MAC more scalable, reliable, and suitable for real-time estimation applications.

</details>


### [2] [Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration](https://arxiv.org/abs/2511.08732)
*Marta Lagomarsino,Elena Merlo,Andrea Pupa,Timo Birr,Franziska Krebs,Cristian Secchi,Tamim Asfour,Arash Ajoudani*

Main category: cs.RO

TL;DR: 这篇综述论文探讨了实现人机协同合作的关键组件，重点关注如何建立双向信息流，让人类能够直观地传达指令和需求，同时机器人能够清晰表达内部状态和未来行动。


<details>
  <summary>Details</summary>
Motivation: 当前机器人和AI虽然具备强大能力，但人类往往只是被动观察者，而机器人在人类环境中无法充分发挥潜力。需要建立有效的人机信息交换机制来实现协同合作。

Method: 通过分析完整的人机交互流程：从多模态输入到机器人可理解表示的转换，到自适应规划和角色分配，再到控制层和反馈机制，形成一个闭环系统。

Result: 识别并连接了实现直观信息交换和技能转移的关键组件，建立了人机协同合作的理论框架。

Conclusion: 论文指出了实现更自适应、更易访问的人机协同合作的趋势和前景方向，为实现真正的人机协同提供了系统性的解决方案。

Abstract: Remarkable capabilities have been achieved by robotics and AI, mastering complex tasks and environments. Yet, humans often remain passive observers, fascinated but uncertain how to engage. Robots, in turn, cannot reach their full potential in human-populated environments without effectively modeling human states and intentions and adapting their behavior. To achieve a synergistic human-robot collaboration (HRC), a continuous information flow should be established: humans must intuitively communicate instructions, share expertise, and express needs. In parallel, robots must clearly convey their internal state and forthcoming actions to keep users informed, comfortable, and in control. This review identifies and connects key components enabling intuitive information exchange and skill transfer between humans and robots. We examine the full interaction pipeline: from the human-to-robot communication bridge translating multimodal inputs into robot-understandable representations, through adaptive planning and role allocation, to the control layer and feedback mechanisms to close the loop. Finally, we highlight trends and promising directions toward more adaptive, accessible HRC.

</details>


### [3] [ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements](https://arxiv.org/abs/2511.08741)
*Kai S. Yun,Navid Azizan*

Main category: cs.RO

TL;DR: ATOM-CBF是一个新颖的安全控制框架，通过显式计算和适应OoD测量中的认知不确定性来确保系统安全，无需真实标签或分布偏移信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统中的学习感知模块容易受到认知不确定性的影响，在遇到训练时未见过的OoD测量时会失效，这给系统安全带来挑战。

Method: 提出ATOM-CBF框架，包含两个关键组件：(1) OoD感知的自适应感知误差边界；(2) 集成该自适应误差边界的安全过滤器，能够实时调整其保守程度。

Result: 在仿真中进行了实证验证，证明ATOM-CBF能够为配备LiDAR扫描的F1Tenth车辆和配备RGB图像的四足机器人保持安全性。

Conclusion: ATOM-CBF框架能够有效处理OoD测量中的认知不确定性，为依赖学习感知模块的现实系统提供安全保障。

Abstract: Ensuring the safety of real-world systems is challenging, especially when they rely on learned perception modules to infer the system state from high-dimensional sensor data. These perception modules are vulnerable to epistemic uncertainty, often failing when encountering out-of-distribution (OoD) measurements not seen during training. To address this gap, we introduce ATOM-CBF (Adaptive-To-OoD-Measurement Control Barrier Function), a novel safe control framework that explicitly computes and adapts to the epistemic uncertainty from OoD measurements, without the need for ground-truth labels or information on distribution shifts. Our approach features two key components: (1) an OoD-aware adaptive perception error margin and (2) a safety filter that integrates this adaptive error margin, enabling the filter to adjust its conservatism in real-time. We provide empirical validation in simulations, demonstrating that ATOM-CBF maintains safety for an F1Tenth vehicle with LiDAR scans and a quadruped robot with RGB images.

</details>


### [4] [CENIC: Convex Error-controlled Numerical Integration for Contact](https://arxiv.org/abs/2511.08771)
*Vince Kurtz,Alejandro Castro*

Main category: cs.RO

TL;DR: CENIC是一个新的连续时间积分器，结合了凸时间步进和误差控制积分的最新进展，在保持实时速度的同时提供精度和收敛性保证。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模拟器使用离散时间步长，需要在精度和速度之间权衡：大步长会产生非物理伪影，小步长则运行缓慢。误差控制积分可以自动调整步长，但现有方法无法处理接触刚度问题，也无法满足现代机器人工作流的速度和可扩展性要求。

Method: CENIC结合了凸时间步进和误差控制积分的最新进展，继承了连续积分和离散时间步进的优点。

Result: CENIC运行速度与MuJoCo、Drake和Isaac Sim等离散时间机器人模拟器相当，达到快速实时速率，同时提供精度和收敛性保证。

Conclusion: CENIC成功解决了离散时间模拟器的时间步长选择难题，在保持实时性能的同时提供了连续时间积分的精度优势。

Abstract: State-of-the-art robotics simulators operate in discrete time. This requires users to choose a time step, which is both critical and challenging: large steps can produce non-physical artifacts, while small steps force the simulation to run slowly. Continuous-time error-controlled integration avoids such issues by automatically adjusting the time step to achieve a desired accuracy. But existing error-controlled integrators struggle with the stiff dynamics of contact, and cannot meet the speed and scalability requirements of modern robotics workflows. We introduce CENIC, a new continuous-time integrator that brings together recent advances in convex time-stepping and error-controlled integration, inheriting benefits from both continuous integration and discrete time-stepping. CENIC runs at fast real-time rates comparable to discrete-time robotics simulators like MuJoCo, Drake and Isaac Sim, while also providing guarantees on accuracy and convergence.

</details>


### [5] [Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains](https://arxiv.org/abs/2511.08778)
*Richard Cheng,Peter Werner,Carolyn Matl*

Main category: cs.RO

TL;DR: 提出了一种针对高自由度双臂机器人的实时运动规划方法，通过利用共享关节（如躯干关节）的结构来缓解维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 高自由度双臂机器人在未知、变化的环境中实时运动规划面临挑战，主要由于配置空间的高维度和复杂的避障约束。

Method: 为每个运动链（左臂+躯干、右臂+躯干）构建动态路线图，利用共享关节的结构特性，通过高效搜索两个路线图的组合来规避维度灾难。

Result: 在真实世界杂货店环境中，使用19自由度移动操作机器人执行杂货配送任务，平均规划时间0.4秒，成功率99.9%，超过2000次运动规划。

Conclusion: 该方法成功缓解了高维运动规划的维度灾难问题，实现了双臂机器人在复杂环境中的高效实时规划。

Abstract: High degree-of-freedom dual-arm robots are becoming increasingly common due to their morphology enabling them to operate effectively in human environments. However, motion planning in real-time within unknown, changing environments remains a challenge for such robots due to the high dimensionality of the configuration space and the complex collision-avoidance constraints that must be obeyed. In this work, we propose a novel way to alleviate the curse of dimensionality by leveraging the structure imposed by shared joints (e.g. torso joints) in a dual-arm robot. First, we build two dynamic roadmaps (DRM) for each kinematic chain (i.e. left arm + torso, right arm + torso) with specific structure induced by the shared joints. Then, we show that we can leverage this structure to efficiently search through the composition of the two roadmaps and largely sidestep the curse of dimensionality. Finally, we run several experiments in a real-world grocery store with this motion planner on a 19 DoF mobile manipulation robot executing a grocery fulfillment task, achieving 0.4s average planning times with 99.9% success rate across more than 2000 motion plans.

</details>


### [6] [Low-cost Multi-agent Fleet for Acoustic Cooperative Localization Research](https://arxiv.org/abs/2511.08822)
*Nelson Durrant,Braden Meyers,Matthew McMurray,Clayton Smith,Brighton Anderson,Tristan Hodgins,Kalliyan Velasco,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: CoUGARs是一个低成本、可配置的自主水下机器人平台，用于多智能体自主性研究，成本低于3000美元，基于商用和3D打印部件，支持声学协作定位研究。


<details>
  <summary>Details</summary>
Motivation: 现实世界水下多智能体自主性测试面临巨大的财务和工程挑战，需要开发低成本、可配置的解决方案。

Method: 开发基于商用和3D打印部件的自主水下机器人平台，配备DVL和USBL声学阵列/传感器，采用容器化软件栈并与HoloOcean模拟器集成。

Result: 系统在模拟和犹他州湖泊水库的现场试验中进行了测试，支持声学协作定位研究。

Conclusion: CoUGARs平台为多智能体自主性研究提供了低成本、可配置的解决方案，成功实现了软硬件集成和实地测试。

Abstract: Real-world underwater testing for multi-agent autonomy presents substantial financial and engineering challenges. In this work, we introduce the Configurable Underwater Group of Autonomous Robots (CoUGARs) as a low-cost, configurable autonomous-underwater-vehicle (AUV) platform for multi-agent autonomy research. The base design costs less than $3,000 USD (as of May 2025) and is based on commercially-available and 3D-printed parts, enabling quick customization for various sensor payloads and configurations. Our current expanded model is equipped with a doppler velocity log (DVL) and ultra-short-baseline (USBL) acoustic array/transducer to support research on acoustic-based cooperative localization. State estimation, navigation, and acoustic communications software has been developed and deployed using a containerized software stack and is tightly integrated with the HoloOcean simulator. The system was tested both in simulation and via in-situ field trials in Utah lakes and reservoirs.

</details>


### [7] [XPRESS: X-Band Radar Place Recognition via Elliptical Scan Shaping](https://arxiv.org/abs/2511.08863)
*Hyesu Jang,Wooseong Yang,Ayoung Kim,Dongje Lee,Hanguen Kim*

Main category: cs.RO

TL;DR: 本文提出了一种专门针对X波段雷达的场所识别算法，通过基于目标密度的候选选择规则和故意降低雷达检测精度来实现稳健的检索性能，用于海上自主导航。


<details>
  <summary>Details</summary>
Motivation: X波段雷达作为海上船舶的主要传感器，在自主导航中应用受限，主要原因是传感器分辨率低和信息内容不足。

Method: 提出X波段雷达专用场所识别算法，包含基于目标密度的候选选择规则和故意降低雷达检测精度的策略。

Result: 在公共海上雷达数据集和自收集数据集上评估算法性能，并与最先进的雷达场所识别方法进行比较，进行了消融研究评估关键参数敏感性。

Conclusion: 所提出的算法能够有效实现X波段雷达在海上环境中的自主导航应用。

Abstract: X-band radar serves as the primary sensor on maritime vessels, however, its application in autonomous navigation has been limited due to low sensor resolution and insufficient information content. To enable X-band radar-only autonomous navigation in maritime environments, this paper proposes a place recognition algorithm specifically tailored for X-band radar, incorporating an object density-based rule for efficient candidate selection and intentional degradation of radar detections to achieve robust retrieval performance. The proposed algorithm was evaluated on both public maritime radar datasets and our own collected dataset, and its performance was compared against state-of-the-art radar place recognition methods. An ablation study was conducted to assess the algorithm's performance sensitivity with respect to key parameters.

</details>


### [8] [MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror](https://arxiv.org/abs/2511.08865)
*Cong Tai,Hansheng Wu,Haixu Long,Zhengbin Long,Zhaoyu Zheng,Haodong Xiang,Tao Shen*

Main category: cs.RO

TL;DR: 提出基于PICO的机器人远程操作框架，实现低成本实时手部运动捕捉，兼容RealMirror生态系统，支持机器人轨迹记录和实时遥操作。


<details>
  <summary>Details</summary>
Motivation: 降低上肢机器人操作研究的技术门槛，加速视觉-语言-动作(VLA)相关研究的进展。

Method: 开发PICO-based机器人远程操作框架，实现低成本实时手部运动姿态数据采集，兼容RealMirror生态系统，在Isaac仿真环境中提供稳定精确的机器人轨迹记录功能。

Result: 该框架在成本效益方面优于主流视觉跟踪和动作捕捉方案，支持多种末端执行器机器人的实时遥操作，包括灵巧手和机器人夹爪。

Conclusion: 该工作为VLA数据集构建提供了现成可用的解决方案，有效促进了上肢机器人操作研究的发展。

Abstract: In this work, we present a PICO-based robot remote operating framework that enables low-cost, real-time acquisition of hand motion and pose data, outperforming mainstream visual tracking and motion capture solutions in terms of cost-effectiveness. The framework is natively compatible with the RealMirror ecosystem, offering ready-to-use functionality for stable and precise robotic trajectory recording within the Isaac simulation environment, thereby facilitating the construction of Vision-Language-Action (VLA) datasets. Additionally, the system supports real-time teleoperation of a variety of end-effector-equipped robots, including dexterous hands and robotic grippers. This work aims to lower the technical barriers in the study of upper-limb robotic manipulation, thereby accelerating advancements in VLA-related research.

</details>


### [9] [A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction](https://arxiv.org/abs/2511.08912)
*Jinyu Zhang,Lijun Han,Feng Jian,Lingxi Zhang,Hesheng Wang*

Main category: cs.RO

TL;DR: 提出了一种具有规划级意图预测的移动机器人共享控制框架，通过深度强化学习联合解决意图域预测和路径重规划问题，显著降低了操作员工作量并提高了安全性。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人共享控制中，有效理解人类运动意图对于实现无缝人机协作至关重要。

Method: 设计了路径重规划算法，引入意图域概念表示未来运动意图，将意图域预测和路径重规划问题联合建模为马尔可夫决策过程并通过深度强化学习求解，开发了基于Voronoi的人类轨迹生成算法实现全仿真训练。

Result: 大量仿真和真实用户研究表明，该方法显著降低了操作员工作量并提高了安全性，与现有辅助遥操作方法相比不牺牲任务效率。

Conclusion: 该共享控制框架通过规划级意图预测和深度强化学习实现了高效的人机协作，在保持任务效率的同时显著改善了用户体验和安全性。

Abstract: In mobile robot shared control, effectively understanding human motion intention is critical for seamless human-robot collaboration. This paper presents a novel shared control framework featuring planning-level intention prediction. A path replanning algorithm is designed to adjust the robot's desired trajectory according to inferred human intentions. To represent future motion intentions, we introduce the concept of an intention domain, which serves as a constraint for path replanning. The intention-domain prediction and path replanning problems are jointly formulated as a Markov Decision Process and solved through deep reinforcement learning. In addition, a Voronoi-based human trajectory generation algorithm is developed, allowing the model to be trained entirely in simulation without human participation or demonstration data. Extensive simulations and real-world user studies demonstrate that the proposed method significantly reduces operator workload and enhances safety, without compromising task efficiency compared with existing assistive teleoperation approaches.

</details>


### [10] [Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation](https://arxiv.org/abs/2511.08935)
*Ningnan Wang,Weihuang Chen,Liming Chen,Haoxuan Ji,Zhongyu Guo,Xuchong Zhang,Hongbin Sun*

Main category: cs.RO

TL;DR: SCOPE是一个零样本视觉导航框架，通过显式利用边界信息驱动基于潜力的探索，结合时空潜力图和自我重新考虑机制，在未知环境中实现更明智的目标相关决策。


<details>
  <summary>Details</summary>
Motivation: 现有零样本研究虽然通过记忆机制改进了长时程规划性能，但忽视了视觉边界对轨迹和观察的根本影响，且未能推断部分视觉观察与导航目标之间的关系。

Method: 提出SCOPE框架：1）使用视觉语言模型估计探索潜力；2）构建时空潜力图捕捉边界动态；3）引入自我重新考虑机制重新评估和优化先前决策。

Result: 在两个不同的具身导航任务上，SCOPE在准确率上比最先进基线方法高出4.6%，其核心组件带来了更好的校准、更强的泛化能力和更高的决策质量。

Conclusion: SCOPE通过显式利用边界信息和自我重新考虑机制，有效提升了零样本视觉导航的性能，证明了边界驱动探索在未知环境导航中的重要性。

Abstract: Embodied visual navigation remains a challenging task, as agents must explore unknown environments with limited knowledge. Existing zero-shot studies have shown that incorporating memory mechanisms to support goal-directed behavior can improve long-horizon planning performance. However, they overlook visual frontier boundaries, which fundamentally dictate future trajectories and observations, and fall short of inferring the relationship between partial visual observations and navigation goals. In this paper, we propose Semantic Cognition Over Potential-based Exploration (SCOPE), a zero-shot framework that explicitly leverages frontier information to drive potential-based exploration, enabling more informed and goal-relevant decisions. SCOPE estimates exploration potential with a Vision-Language Model and organizes it into a spatio-temporal potential graph, capturing boundary dynamics to support long-horizon planning. In addition, SCOPE incorporates a self-reconsideration mechanism that revisits and refines prior decisions, enhancing reliability and reducing overconfident errors. Experimental results on two diverse embodied navigation tasks show that SCOPE outperforms state-of-the-art baselines by 4.6\% in accuracy. Further analysis demonstrates that its core components lead to improved calibration, stronger generalization, and higher decision quality.

</details>


### [11] [Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning](https://arxiv.org/abs/2511.08942)
*Mobin Habibpour,Fatemeh Afghah*

Main category: cs.RO

TL;DR: 该论文提出了一种新框架，将视觉语言模型从被动观察者转变为主动策略制定者，通过结构化思维链提示、动态动作历史集成和障碍物地图解释技术，显著提升了机器人导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用视觉语言模型的推理能力，为了释放其在机器人导航中的全部潜力，需要将其角色从被动观察者转变为主动策略制定者。

Method: 采用结构化思维链提示激发逻辑推理，动态集成智能体近期动作历史防止陷入循环，以及让VLM能够解释俯视障碍物地图和第一人称视图以增强空间感知。

Result: 在HM3D、Gibson和MP3D等挑战性基准测试中，该方法产生了极其直接和逻辑的轨迹，导航效率相比现有方法有显著提升。

Conclusion: 该方法为开发更强大的具身智能体开辟了新路径，通过将VLM作为主动策略制定者，实现了导航效率的实质性改进。

Abstract: While Vision-Language Models (VLMs) are set to transform robotic navigation, existing methods often underutilize their reasoning capabilities. To unlock the full potential of VLMs in robotics, we shift their role from passive observers to active strategists in the navigation process. Our framework outsources high-level planning to a VLM, which leverages its contextual understanding to guide a frontier-based exploration agent. This intelligent guidance is achieved through a trio of techniques: structured chain-of-thought prompting that elicits logical, step-by-step reasoning; dynamic inclusion of the agent's recent action history to prevent getting stuck in loops; and a novel capability that enables the VLM to interpret top-down obstacle maps alongside first-person views, thereby enhancing spatial awareness. When tested on challenging benchmarks like HM3D, Gibson, and MP3D, this method produces exceptionally direct and logical trajectories, marking a substantial improvement in navigation efficiency over existing approaches and charting a path toward more capable embodied agents.

</details>


### [12] [UniMM-V2X: MoE-Enhanced Multi-Level Fusion for End-to-End Cooperative Autonomous Driving](https://arxiv.org/abs/2511.09013)
*Ziyi Song,Chen Xia,Chenbing Wang,Haibao Yu,Sheng Zhou,Zhisheng Niu*

Main category: cs.RO

TL;DR: UniMM-V2X是一个新颖的端到端多智能体框架，实现了感知、预测和规划的层次化协作，通过多级融合策略和混合专家架构显著提升了自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统存在感知有限和决策孤立的问题，现有多智能体方法主要关注感知层面，忽视了与下游规划和控制的协调，未能充分利用端到端自动驾驶的潜力。

Method: 提出多级融合策略统一感知和预测协作，让智能体共享查询并协同推理；引入混合专家架构动态增强BEV表示，并将MoE扩展到解码器以捕捉多样化运动模式。

Result: 在DAIR-V2X数据集上的实验表明，相比UniV2X，感知精度提升39.7%，预测误差降低7.2%，规划性能提升33.2%，达到最先进水平。

Conclusion: MoE增强的多级协作范式展示了强大的性能，为端到端自动驾驶系统提供了有效的多智能体协作解决方案。

Abstract: Autonomous driving holds transformative potential but remains fundamentally constrained by the limited perception and isolated decision-making with standalone intelligence. While recent multi-agent approaches introduce cooperation, they often focus merely on perception-level tasks, overlooking the alignment with downstream planning and control, or fall short in leveraging the full capacity of the recent emerging end-to-end autonomous driving. In this paper, we present UniMM-V2X, a novel end-to-end multi-agent framework that enables hierarchical cooperation across perception, prediction, and planning. At the core of our framework is a multi-level fusion strategy that unifies perception and prediction cooperation, allowing agents to share queries and reason cooperatively for consistent and safe decision-making. To adapt to diverse downstream tasks and further enhance the quality of multi-level fusion, we incorporate a Mixture-of-Experts (MoE) architecture to dynamically enhance the BEV representations. We further extend MoE into the decoder to better capture diverse motion patterns. Extensive experiments on the DAIR-V2X dataset demonstrate our approach achieves state-of-the-art (SOTA) performance with a 39.7% improvement in perception accuracy, a 7.2% reduction in prediction error, and a 33.2% improvement in planning performance compared with UniV2X, showcasing the strength of our MoE-enhanced multi-level cooperative paradigm.

</details>


### [13] [A Quantum Tunneling and Bio-Phototactic Driven Enhanced Dwarf Mongoose Optimizer for UAV Trajectory Planning and Engineering Problem](https://arxiv.org/abs/2511.09020)
*Mingyang Yu,Haorui Yang,Kangning An,Xinjian Wei,Xiaoxuan Xu,Jing Xu*

Main category: cs.RO

TL;DR: 本文提出了一种增强型多策略矮獴优化算法(EDMO)，用于解决三维无人机路径规划问题。该算法集成了三种新颖策略来克服传统元启发式算法的局限性，在复杂动态环境中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 随着无人机的广泛应用，有效的路径规划变得日益重要。传统元启发式算法虽然高效，但在复杂场景中仍面临早熟收敛和解决方案多样性不足的问题，需要改进算法性能。

Method: EDMO算法集成了三种策略：(1)动态量子隧道优化策略(DQTOS)，使粒子概率性地逃离局部最优；(2)生物趋光动态聚焦搜索策略(BDFSS)，受微生物趋光性启发进行自适应局部细化；(3)正交透镜对立学习策略(OLOBL)，通过结构化维度重组增强全局探索。

Result: 在CEC2017和CEC2020的39个标准测试函数上，EDMO优于14种先进算法，在收敛速度、鲁棒性和优化精度方面表现优异。在无人机三维路径规划和三个工程设计任务中的实际验证证实了其实际应用价值。

Conclusion: EDMO算法在复杂动态环境中表现出卓越性能，为需要智能、自适应和高效规划的现场机器人任务提供了有效的解决方案。

Abstract: With the widespread adoption of unmanned aerial vehicles (UAV), effective path planning has become increasingly important. Although traditional search methods have been extensively applied, metaheuristic algorithms have gained popularity due to their efficiency and problem-specific heuristics. However, challenges such as premature convergence and lack of solution diversity still hinder their performance in complex scenarios. To address these issues, this paper proposes an Enhanced Multi-Strategy Dwarf Mongoose Optimization (EDMO) algorithm, tailored for three-dimensional UAV trajectory planning in dynamic and obstacle-rich environments. EDMO integrates three novel strategies: (1) a Dynamic Quantum Tunneling Optimization Strategy (DQTOS) to enable particles to probabilistically escape local optima; (2) a Bio-phototactic Dynamic Focusing Search Strategy (BDFSS) inspired by microbial phototaxis for adaptive local refinement; and (3) an Orthogonal Lens Opposition-Based Learning (OLOBL) strategy to enhance global exploration through structured dimensional recombination. EDMO is benchmarked on 39 standard test functions from CEC2017 and CEC2020, outperforming 14 advanced algorithms in convergence speed, robustness, and optimization accuracy. Furthermore, real-world validations on UAV three-dimensional path planning and three engineering design tasks confirm its practical applicability and effectiveness in field robotics missions requiring intelligent, adaptive, and time-efficient planning.

</details>


### [14] [D-AWSIM: Distributed Autonomous Driving Simulator for Dynamic Map Generation Framework](https://arxiv.org/abs/2511.09080)
*Shunsuke Ito,Chaoran Zhao,Ryo Okamura,Takuya Azumi*

Main category: cs.RO

TL;DR: D-AWSIM是一个分布式模拟器，通过在多台机器上分配工作负载来支持大规模传感器部署和密集交通环境的仿真，解决了传统单机模拟器无法处理大规模城市交通场景的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在特定操作设计域内取得了显著进展，但扩展这些域需要在多样化条件下解决安全保障问题。信息共享通过车对车和车对基础设施通信提供有前景的解决方案，但现实世界实验成本高昂且面临监管挑战。

Method: 提出D-AWSIM分布式模拟器，将工作负载分配到多台机器上，支持大规模传感器部署和密集交通环境仿真。在D-AWSIM上构建动态地图生成框架，使研究人员能够在不依赖物理测试平台的情况下探索信息共享策略。

Result: 评估显示，与单机设置相比，D-AWSIM在车辆数量和LiDAR传感器处理方面的吞吐量显著提高。与Autoware的集成证明了其在自动驾驶研究中的适用性。

Conclusion: D-AWSIM为自动驾驶研究提供了一个高效的大规模仿真平台，能够支持复杂传感器部署和密集交通环境的模拟，为信息共享策略研究提供了可行替代方案。

Abstract: Autonomous driving systems have achieved significant advances, and full autonomy within defined operational design domains near practical deployment. Expanding these domains requires addressing safety assurance under diverse conditions. Information sharing through vehicle-to-vehicle and vehicle-to-infrastructure communication, enabled by a Dynamic Map platform built from vehicle and roadside sensor data, offers a promising solution. Real-world experiments with numerous infrastructure sensors incur high costs and regulatory challenges. Conventional single-host simulators lack the capacity for large-scale urban traffic scenarios. This paper proposes D-AWSIM, a distributed simulator that partitions its workload across multiple machines to support the simulation of extensive sensor deployment and dense traffic environments. A Dynamic Map generation framework on D-AWSIM enables researchers to explore information-sharing strategies without relying on physical testbeds. The evaluation shows that D-AWSIM increases throughput for vehicle count and LiDAR sensor processing substantially compared to a single-machine setup. Integration with Autoware demonstrates applicability for autonomous driving research.

</details>


### [15] [APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots](https://arxiv.org/abs/2511.09091)
*Shivam Sood,Laukik Nakhwa,Sun Ge,Yuhong Cao,Jin Cheng,Fatemah Zargarbashi,Taerim Yoon,Sungjoon Choi,Stelian Coros,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: APEX是一种即插即用的强化学习方法，通过整合动作先验来消除部署时对参考数据的依赖，提高样本效率并减少参数调优。


<details>
  <summary>Details</summary>
Motivation: 现有运动跟踪方法需要大量调优并在部署时依赖参考数据，限制了适应性。APEX旨在消除这种依赖，提高学习效率和泛化能力。

Method: APEX结合衰减动作先验和多批评器框架，将专家演示直接整合到强化学习中，初始偏向专家演示但逐渐允许独立探索。

Result: 在仿真和Unitree Go2机器人上的实验验证了方法的有效性，能够学习多样化运动并在不同地形和速度间迁移风格。

Conclusion: APEX通过演示引导强化学习探索，使腿式机器人能够以更高的稳定性、效率和泛化能力学习，为从运动到操作的广泛机器人任务提供了指导驱动的强化学习方法。

Abstract: Learning natural, animal-like locomotion from demonstrations has become a core paradigm in legged robotics. Despite the recent advancements in motion tracking, most existing methods demand extensive tuning and rely on reference data during deployment, limiting adaptability. We present APEX (Action Priors enable Efficient Exploration), a plug-and-play extension to state-of-the-art motion tracking algorithms that eliminates any dependence on reference data during deployment, improves sample efficiency, and reduces parameter tuning effort. APEX integrates expert demonstrations directly into reinforcement learning (RL) by incorporating decaying action priors, which initially bias exploration toward expert demonstrations but gradually allow the policy to explore independently. This is combined with a multi-critic framework that balances task performance with motion style. Moreover, APEX enables a single policy to learn diverse motions and transfer reference-like styles across different terrains and velocities, while remaining robust to variations in reward design. We validate the effectiveness of our method through extensive experiments in both simulation and on a Unitree Go2 robot. By leveraging demonstrations to guide exploration during RL training, without imposing explicit bias toward them, APEX enables legged robots to learn with greater stability, efficiency, and generalization. We believe this approach paves the way for guidance-driven RL to boost natural skill acquisition in a wide array of robotic tasks, from locomotion to manipulation. Website and code: https://marmotlab.github.io/APEX/.

</details>


### [16] [Decoupling Torque and Stiffness: A Unified Modeling and Control Framework for Antagonistic Artificial Muscles](https://arxiv.org/abs/2511.09104)
*Amirhossein Kazemipour,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一个统一框架，用于实时独立控制各种软执行器的扭矩和刚度，通过级联控制器和分析逆动力学保持解耦控制，在接触实验中验证了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的软肌肉控制器难以在动态接触瞬态中保持独立的扭矩和刚度控制，限制了软执行器在安全人机交互中的应用。

Method: 采用统一力律捕捉多种软肌肉物理特性，使用级联控制器和分析逆动力学，通过共收缩/偏置坐标独立调节扭矩和刚度。

Result: 仿真验证显示：在软表面上沉降速度快200倍，刚性表面上力减少81%，稳定交互对比固定策略的22-54%稳定性。

Conclusion: 该框架为肌肉骨骼拮抗系统实现自适应阻抗控制提供了基础，支持安全的人机交互。

Abstract: Antagonistic soft actuators built from artificial muscles (PAMs, HASELs, DEAs) promise plant-level torque-stiffness decoupling, yet existing controllers for soft muscles struggle to maintain independent control through dynamic contact transients. We present a unified framework enabling independent torque and stiffness commands in real-time for diverse soft actuator types. Our unified force law captures diverse soft muscle physics in a single model with sub-ms computation, while our cascaded controller with analytical inverse dynamics maintains decoupling despite model errors and disturbances. Using co-contraction/bias coordinates, the controller independently modulates torque via bias and stiffness via co-contraction-replicating biological impedance strategies. Simulation-based validation through contact experiments demonstrates maintained independence: 200x faster settling on soft surfaces, 81% force reduction on rigid surfaces, and stable interaction vs 22-54% stability for fixed policies. This framework provides a foundation for enabling musculoskeletal antagonistic systems to execute adaptive impedance control for safe human-robot interaction.

</details>


### [17] [Data Assessment for Embodied Intelligence](https://arxiv.org/abs/2511.09119)
*Jiahao Xiao,Bowen Yan,Jianbo Zhang,Jia Wang,Chunyi Li,Zhengxue Cheng,Guangtao Zhai*

Main category: cs.RO

TL;DR: 本文提出了两种数据驱动的工具来评估具身智能数据集：多样性熵和可学习性量化算法，旨在解决数据集信息量和可学习性评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 具身智能数据集的多模态特性使得评估其信息量和可学习性变得困难。现有方法主要关注多样性，但缺乏全面评估；而可学习性评估通常需要昂贵的模型训练过程，缺乏可解释性。

Method: 1. 为每个数据样本构建统一的多模态表示，提出多样性熵来连续衡量数据集的信息量；2. 引入首个可解释的数据驱动算法，无需训练即可高效量化数据集的可学习性。

Result: 在模拟和真实世界具身数据集上的验证表明，该算法能够提供可靠的、可操作的见解，使研究人员能够同时改进数据集的多样性和可学习性。

Conclusion: 这项工作为设计更高质量的具身智能数据集奠定了基础，有望推动具身智能的发展。

Abstract: In embodied intelligence, datasets play a pivotal role, serving as both a knowledge repository and a conduit for information transfer. The two most critical attributes of a dataset are the amount of information it provides and how easily this information can be learned by models. However, the multimodal nature of embodied data makes evaluating these properties particularly challenging. Prior work has largely focused on diversity, typically counting tasks and scenes or evaluating isolated modalities, which fails to provide a comprehensive picture of dataset diversity. On the other hand, the learnability of datasets has received little attention and is usually assessed post-hoc through model training, an expensive, time-consuming process that also lacks interpretability, offering little guidance on how to improve a dataset. In this work, we address both challenges by introducing two principled, data-driven tools. First, we construct a unified multimodal representation for each data sample and, based on it, propose diversity entropy, a continuous measure that characterizes the amount of information contained in a dataset. Second, we introduce the first interpretable, data-driven algorithm to efficiently quantify dataset learnability without training, enabling researchers to assess a dataset's learnability immediately upon its release. We validate our algorithm on both simulated and real-world embodied datasets, demonstrating that it yields faithful, actionable insights that enable researchers to jointly improve diversity and learnability. We hope this work provides a foundation for designing higher-quality datasets that advance the development of embodied intelligence.

</details>


### [18] [LODESTAR: Degeneracy-Aware LiDAR-Inertial Odometry with Adaptive Schmidt-Kalman Filter and Data Exploitation](https://arxiv.org/abs/2511.09142)
*Eungchang Mason Lee,Kevin Christiansen Marsim,Hyun Myung*

Main category: cs.RO

TL;DR: LODESTAR是一种新颖的激光雷达-惯性里程计方法，通过退化感知自适应施密特-卡尔曼滤波和退化感知数据利用两个关键模块，解决在退化环境中的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统激光雷达-惯性里程计在退化环境（如长走廊、高空飞行）中性能下降，因为激光雷达测量不平衡或稀疏，导致状态估计不适定。

Method: 采用退化感知自适应施密特-卡尔曼滤波器，使用滑动窗口利用过去状态和测量作为额外约束，根据退化水平自适应分类状态为活动或固定；结合退化感知数据利用模块，修剪信息量较少的测量并选择性利用固定状态的测量。

Result: 实验结果显示LODESTAR在各种退化条件下，在准确性和鲁棒性方面优于现有的基于激光雷达的里程计方法和退化感知模块。

Conclusion: LODESTAR通过退化感知约束优化和测量稀疏性缓解，成功解决了激光雷达-惯性里程计在退化环境中的性能问题。

Abstract: LiDAR-inertial odometry (LIO) has been widely used in robotics due to its high accuracy. However, its performance degrades in degenerate environments, such as long corridors and high-altitude flights, where LiDAR measurements are imbalanced or sparse, leading to ill-posed state estimation. In this letter, we present LODESTAR, a novel LIO method that addresses these degeneracies through two key modules: degeneracy-aware adaptive Schmidt-Kalman filter (DA-ASKF) and degeneracy-aware data exploitation (DA-DE). DA-ASKF employs a sliding window to utilize past states and measurements as additional constraints. Specifically, it introduces degeneracy-aware sliding modes that adaptively classify states as active or fixed based on their degeneracy level. Using Schmidt-Kalman update, it partially optimizes active states while preserving fixed states. These fixed states influence the update of active states via their covariances, serving as reference anchors--akin to a lodestar. Additionally, DA-DE prunes less-informative measurements from active states and selectively exploits measurements from fixed states, based on their localizability contribution and the condition number of the Jacobian matrix. Consequently, DA-ASKF enables degeneracy-aware constrained optimization and mitigates measurement sparsity, while DA-DE addresses measurement imbalance. Experimental results show that LODESTAR outperforms existing LiDAR-based odometry methods and degeneracy-aware modules in terms of accuracy and robustness under various degenerate conditions.

</details>


### [19] [Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots](https://arxiv.org/abs/2511.09241)
*Yuxi Wei,Zirui Wang,Kangning Yin,Yue Hu,Jingbo Wang,Siheng Chen*

Main category: cs.RO

TL;DR: Humanoid-Union是一个通过自主流水线生成的大规模人形机器人运动数据集，包含260多小时多样化高质量运动数据，基于人类运动视频构建。在此基础上提出SCHUR框架，探索大规模数据对人形机器人高级控制的影响，在运动生成质量和文本-运动对齐方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中数据扩展的关键瓶颈，利用丰富的人类视频和运动数据作为免费的大规模数据源，通过语义相关的运动实现模态对齐和高级机器人控制学习。

Method: 开发Humanoid-Union数据集生成流水线，从人类运动视频中提取机器人可学习的表示；提出SCHUR可扩展学习框架，研究大规模数据对人形机器人高级控制的影响。

Result: SCHUR在运动生成质量和文本-运动对齐方面表现优异，与现有方法相比，MPJPE重建指标提升37%，FID对齐指标提升25%，并在真实人形机器人上验证了有效性。

Conclusion: Humanoid-Union数据集和SCHUR框架有效解决了机器人学习中的数据扩展问题，证明了大规模数据对人形机器人高级控制的重要作用，为可扩展的机器人学习提供了新途径。

Abstract: Data scaling has long remained a critical bottleneck in robot learning. For humanoid robots, human videos and motion data are abundant and widely available, offering a free and large-scale data source. Besides, the semantics related to the motions enable modality alignment and high-level robot control learning. However, how to effectively mine raw video, extract robot-learnable representations, and leverage them for scalable learning remains an open problem. To address this, we introduce Humanoid-Union, a large-scale dataset generated through an autonomous pipeline, comprising over 260 hours of diverse, high-quality humanoid robot motion data with semantic annotations derived from human motion videos. The dataset can be further expanded via the same pipeline. Building on this data resource, we propose SCHUR, a scalable learning framework designed to explore the impact of large-scale data on high-level control in humanoid robots. Experimental results demonstrate that SCHUR achieves high robot motion generation quality and strong text-motion alignment under data and model scaling, with 37\% reconstruction improvement under MPJPE and 25\% alignment improvement under FID comparing with previous methods. Its effectiveness is further validated through deployment in real-world humanoid robot.

</details>


### [20] [UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning](https://arxiv.org/abs/2511.09302)
*Yan Huang,Shoujie Li,Xingting Li,Wenbo Ding*

Main category: cs.RO

TL;DR: UMIGen是一个统一框架，包含Cloud-UMI手持数据采集设备和可见性感知优化机制，能够高效生成与真实自我中心3D观测对齐的数据，支持跨机器人具身的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的机器人学习面临困境：鲁棒策略需要大规模高质量演示数据，但数据收集成本高、依赖专用硬件，且当前方法空间泛化能力有限。UMI放松了硬件要求但仅捕获RGB图像，缺乏任务依赖的3D几何信息。

Method: 提出UMIGen框架，包含：(1) Cloud-UMI手持数据采集设备，无需视觉SLAM，同时记录点云观测-动作对；(2) 可见性感知优化机制，将DemoGen管道扩展到自我中心3D观测，仅生成相机视野内的点。

Result: 在模拟和真实环境中的实验表明，UMIGen支持强大的跨具身泛化能力，并在多样化操作任务中加速数据收集。

Conclusion: UMIGen实现了高效的数据生成，与真实自我中心观测对齐，可直接在不同机器人具身间转移，无需后处理。

Abstract: Data-driven robotic learning faces an obvious dilemma: robust policies demand large-scale, high-quality demonstration data, yet collecting such data remains a major challenge owing to high operational costs, dependence on specialized hardware, and the limited spatial generalization capability of current methods. The Universal Manipulation Interface (UMI) relaxes the strict hardware requirements for data collection, but it is restricted to capturing only RGB images of a scene and omits the 3D geometric information on which many tasks rely. Inspired by DemoGen, we propose UMIGen, a unified framework that consists of two key components: (1) Cloud-UMI, a handheld data collection device that requires no visual SLAM and simultaneously records point cloud observation-action pairs; and (2) a visibility-aware optimization mechanism that extends the DemoGen pipeline to egocentric 3D observations by generating only points within the camera's field of view. These two components enable efficient data generation that aligns with real egocentric observations and can be directly transferred across different robot embodiments without any post-processing. Experiments in both simulated and real-world settings demonstrate that UMIGen supports strong cross-embodiment generalization and accelerates data collection in diverse manipulation tasks.

</details>


### [21] [SPIDER: Scalable Physics-Informed Dexterous Retargeting](https://arxiv.org/abs/2511.09484)
*Chaoyi Pan,Changhao Wang,Haozhi Qi,Zixi Liu,Homanga Bharadhwaj,Akash Sharma,Tingfan Wu,Guanya Shi,Jitendra Malik,Francois Hogan*

Main category: cs.RO

TL;DR: SPIDER是一个基于物理的框架，用于将人类运动数据转化为机器人可执行的动态可行轨迹，解决了人类演示与机器人控制之间的数据差距问题。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人和灵巧手控制中数据稀缺问题，利用丰富的人类运动数据来替代昂贵的机器人专用数据收集。

Method: 使用基于物理的重定向框架，通过大规模物理采样和课程式虚拟接触指导，将仅包含运动学信息的人类演示转化为动态可行的机器人轨迹。

Result: 在9种不同的人形/灵巧手实体和6个数据集上验证，成功率比标准采样提高18%，比强化学习基线快10倍，生成了240万帧动态可行机器人数据集。

Conclusion: SPIDER作为一种通用的基于物理的重定向方法，能够处理不同质量的数据并生成多样化高质量数据，有效支持强化学习等策略学习方法。

Abstract: Learning dexterous and agile policy for humanoid and dexterous hand control requires large-scale demonstrations, but collecting robot-specific data is prohibitively expensive. In contrast, abundant human motion data is readily available from motion capture, videos, and virtual reality, which could help address the data scarcity problem. However, due to the embodiment gap and missing dynamic information like force and torque, these demonstrations cannot be directly executed on robots. To bridge this gap, we propose Scalable Physics-Informed DExterous Retargeting (SPIDER), a physics-based retargeting framework to transform and augment kinematic-only human demonstrations to dynamically feasible robot trajectories at scale. Our key insight is that human demonstrations should provide global task structure and objective, while large-scale physics-based sampling with curriculum-style virtual contact guidance should refine trajectories to ensure dynamical feasibility and correct contact sequences. SPIDER scales across diverse 9 humanoid/dexterous hand embodiments and 6 datasets, improving success rates by 18% compared to standard sampling, while being 10X faster than reinforcement learning (RL) baselines, and enabling the generation of a 2.4M frames dynamic-feasible robot dataset for policy learning. As a universal physics-based retargeting method, SPIDER can work with diverse quality data and generate diverse and high-quality data to enable efficient policy learning with methods like RL.

</details>


### [22] [WMPO: World Model-based Policy Optimization for Vision-Language-Action Models](https://arxiv.org/abs/2511.09515)
*Fangqi Zhu,Zhengyang Yan,Zicong Hong,Quanxin Shou,Xiao Ma,Song Guo*

Main category: cs.RO

TL;DR: WMPO是一个基于世界模型的策略优化框架，用于视觉-语言-动作模型的在线强化学习，无需与真实环境交互，显著提高了样本效率并实现了自我纠正等涌现行为。


<details>
  <summary>Details</summary>
Motivation: VLA模型依赖专家演示，无法从失败中学习；强化学习样本复杂度高。需要一种能在不接触真实环境的情况下进行在线RL的方法。

Method: 提出WMPO框架，使用基于像素预测的世界模型，将"想象"轨迹与预训练的VLA特征对齐，实现在线GRPO策略优化。

Result: 在仿真和真实机器人实验中，WMPO显著提高样本效率，获得更强性能，涌现自我纠正行为，并展示鲁棒泛化和终身学习能力。

Conclusion: WMPO为VLA模型提供了一种高效的在线强化学习方法，无需真实环境交互，实现了自我改进和泛化能力。

Abstract: Vision-Language-Action (VLA) models have shown strong potential for general-purpose robotic manipulation, but their reliance on expert demonstrations limits their ability to learn from failures and perform self-corrections. Reinforcement learning (RL) addresses these through self-improving interactions with the physical environment, but suffers from high sample complexity on real robots. We introduce World-Model-based Policy Optimization (WMPO), a principled framework for on-policy VLA RL without interacting with the real environment. In contrast to widely used latent world models, WMPO focuses on pixel-based predictions that align the "imagined" trajectories with the VLA features pretrained with web-scale images. Crucially, WMPO enables the policy to perform on-policy GRPO that provides stronger performance than the often-used off-policy methods. Extensive experiments in both simulation and real-robot settings demonstrate that WMPO (i) substantially improves sample efficiency, (ii) achieves stronger overall performance, (iii) exhibits emergent behaviors such as self-correction, and (iv) demonstrates robust generalization and lifelong learning capabilities.

</details>


### [23] [MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation](https://arxiv.org/abs/2511.09516)
*Runhao Li,Wenkai Guo,Zhenyu Wu,Changyuan Wang,Haoyuan Deng,Zhenyu Weng,Yap-Peng Tan,Ziwei Wang*

Main category: cs.RO

TL;DR: MAP-VLA提出了一种记忆增强提示框架，通过从历史演示中构建记忆库并动态检索相关记忆来增强预训练VLA模型在长时程机器人操作任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉-语言-动作模型在长时程任务中表现不佳，因为它们缺乏记忆能力且仅依赖即时感官输入。

Method: 构建记忆库存储任务各阶段信息作为可学习软提示，通过轨迹相似性匹配实时检索相关记忆并集成到冻结的VLA模型中。

Result: 在仿真基准测试中实现7.0%的绝对性能提升，在真实机器人评估中实现25.0%的性能提升，超越当前最先进方法。

Conclusion: MAP-VLA提供了一种轻量级、灵活的即插即用解决方案，显著提升了预训练VLA模型在长时程机器人操作任务中的性能。

Abstract: Pre-trained Vision-Language-Action (VLA) models have achieved remarkable success in improving robustness and generalization for end-to-end robotic manipulation. However, these models struggle with long-horizon tasks due to their lack of memory and reliance solely on immediate sensory inputs. To address this limitation, we propose Memory-Augmented Prompting for Vision-Language-Action model (MAP-VLA), a novel framework that empowers pre-trained VLA models with demonstration-derived memory prompts to augment action generation for long-horizon robotic manipulation tasks. To achieve this, MAP-VLA first constructs a memory library from historical demonstrations, where each memory unit captures information about a specific stage of a task. These memory units are implemented as learnable soft prompts optimized through prompt tuning. Then, during real-time task execution, MAP-VLA retrieves relevant memory through trajectory similarity matching and dynamically integrates it into the VLA model for augmented action generation. Importantly, this prompt tuning and retrieval augmentation approach operates as a plug-and-play module for a frozen VLA model, offering a lightweight and flexible solution to improve task performance. Experimental results show that MAP-VLA delivers up to 7.0% absolute performance gains in the simulation benchmark and 25.0% on real robot evaluations for long-horizon tasks, surpassing the current state-of-the-art methods.

</details>
