{"id": "2511.07654", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07654", "abs": "https://arxiv.org/abs/2511.07654", "authors": ["Yinsen Jia", "Boyuan Chen"], "title": "Time-Aware Policy Learning for Adaptive and Punctual Robot Control", "comment": null, "summary": "Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5269\u4f59\u65f6\u95f4\u548c\u65f6\u95f4\u6bd4\u7387\u4f5c\u4e3a\u989d\u5916\u4fe1\u53f7\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5c06\u65f6\u95f4\u4f5c\u4e3a\u7b2c\u4e00\u7c7b\u53d8\u91cf\u8fdb\u884c\u611f\u77e5\u548c\u63a8\u7406\uff0c\u4ece\u800c\u5728\u5355\u4e00\u7b56\u7565\u4e2d\u5b9e\u73b0\u4ece\u5feb\u901f\u52a8\u6001\u5230\u8c28\u614e\u7cbe\u786e\u7684\u8fde\u7eed\u884c\u4e3a\u8c03\u8282\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u673a\u5668\u4eba\u5b66\u4e60\u7b97\u6cd5\u5bf9\u65f6\u95f4\u611f\u77e5\u4e0d\u8db3\uff0c\u800c\u65f6\u95f4\u610f\u8bc6\u662f\u52a8\u7269\u548c\u4eba\u7c7b\u667a\u80fd\u884c\u4e3a\u7684\u57fa\u7840\u3002\u4e3a\u4e86\u8d4b\u4e88\u673a\u5668\u4eba\u660e\u786e\u7684\u65f6\u95f4\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u65f6\u95f4\u7ea6\u675f\u81ea\u9002\u5e94\u8c03\u6574\u884c\u4e3a\u3002", "method": "\u5728\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u57fa\u7840\u4e0a\u5f15\u5165\u4e24\u4e2a\u4e92\u8865\u7684\u65f6\u95f4\u4fe1\u53f7\uff1a\u5269\u4f59\u65f6\u95f4\u548c\u65f6\u95f4\u6bd4\u7387\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u51c6\u65f6\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5728\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5956\u52b1\u8c03\u6574\u7684\u60c5\u51b5\u4e0b\u5e73\u8861\u6548\u7387\u3001\u9c81\u68d2\u6027\u3001\u5f39\u6027\u548c\u51c6\u65f6\u6027\u3002", "result": "\u5728\u591a\u79cd\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u76f8\u6bd4\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u5728\u6548\u7387\u4e0a\u63d0\u5347\u9ad8\u8fbe48%\uff0c\u5728\u4eff\u771f\u5230\u73b0\u5b9e\u8fc1\u79fb\u4e2d\u9c81\u68d2\u6027\u63d0\u9ad88\u500d\uff0c\u58f0\u5b66\u5b89\u9759\u5ea6\u63d0\u534790%\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u65f6\u95f4\u89c6\u4e3a\u884c\u4e3a\u7684\u53ef\u63a7\u7ef4\u5ea6\u800c\u975e\u7ea6\u675f\uff0c\u65f6\u95f4\u611f\u77e5\u7b56\u7565\u5b66\u4e60\u4e3a\u9ad8\u6548\u3001\u9c81\u68d2\u3001\u5f39\u6027\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u63d0\u4f9b\u4e86\u7edf\u4e00\u57fa\u7840\uff0c\u8fdb\u4e00\u6b65\u652f\u6301\u5b9e\u65f6\u4eba\u673a\u4ea4\u4e92\u63a7\u5236\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u3002"}}
{"id": "2511.08005", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08005", "abs": "https://arxiv.org/abs/2511.08005", "authors": ["Huacen Wang", "Hongqiang Wang"], "title": "A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake", "comment": null, "summary": "Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u96c6\u6210\u5236\u52a8\u529f\u80fd\u7684\u4e24\u5c42\u9759\u7535\u8584\u819c\u6267\u884c\u5668\uff0c\u901a\u8fc7\u5728\u9876\u5c42\u548c\u5e95\u5c42\u4ea4\u66ff\u5206\u5e03\u7535\u6781\uff0c\u5728\u76f8\u540c\u5236\u9020\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u5c0f\u7684\u6709\u6548\u7535\u6781\u95f4\u8ddd\uff0c\u4f7f\u9a71\u52a8\u529b\u8fbe\u5230\u7ea6241 N/m\u00b2\uff0c\u6bd4\u4e4b\u524d\u7684\u4e09\u76f8\u6267\u884c\u5668\u63d0\u9ad8\u4e8690.5%\u3002", "motivation": "\u4f20\u7edf\u7535\u673a\u9a71\u52a8\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u5b58\u5728\u8d28\u91cf\u5927\u3001\u63a7\u5236\u7b97\u6cd5\u590d\u6742\u3001\u9700\u8981\u989d\u5916\u5236\u52a8\u673a\u5236\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u8f7b\u91cf\u7d27\u51d1\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5e94\u7528\u3002\u9759\u7535\u8584\u819c\u6267\u884c\u5668\u867d\u7136\u5177\u6709\u8584\u3001\u67d4\u3001\u8f7b\u3001\u9ad8\u5f00\u73af\u5b9a\u4f4d\u7cbe\u5ea6\u7b49\u4f18\u70b9\uff0c\u4f46\u4f20\u7edf\u4e09\u76f8\u7535\u6781\u8bbe\u8ba1\u7684\u9a71\u52a8\u529b\u4ecd\u6709\u5f85\u63d0\u9ad8\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u5c42\u9759\u7535\u8584\u819c\u6267\u884c\u5668\uff0c\u5728\u9876\u5c42\u548c\u5e95\u5c42\u4ea4\u66ff\u5206\u5e03\u7535\u6781\uff0c\u5b9e\u73b0\u66f4\u5c0f\u7684\u6709\u6548\u7535\u6781\u95f4\u8ddd\u3002\u540c\u65f6\u96c6\u6210\u4e86\u9759\u7535\u7c98\u9644\u673a\u5236\uff0c\u53ef\u5728\u5236\u52a8\u6a21\u5f0f\u4e0b\u4fdd\u6301\u8d1f\u8f7d\u3002", "result": "\u6267\u884c\u5668\u9a71\u52a8\u529b\u8fbe\u5230\u7ea6241 N/m\u00b2\uff0c\u6bd4\u4e4b\u524d\u7684\u4e09\u76f8\u6267\u884c\u5668\u63d0\u9ad8\u4e8690.5%\u3002\u901a\u8fc7\u591a\u4e2a\u6f14\u793a\u9a8c\u8bc1\u4e86\u5176\u5728\u9a71\u52a8\u548c\u5236\u52a8\u6a21\u5f0f\u4e0b\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5305\u62ec\u4e0e\u4f20\u7edf\u5355\u5c42\u6267\u884c\u5668\u7684\u62d4\u6cb3\u6d4b\u8bd5\u3001\u8d1f\u8f7d\u64cd\u4f5c\u3001\u5355\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u548c\u53cc\u6a21\u5f0f\u5939\u722a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e24\u5c42\u9759\u7535\u8584\u819c\u6267\u884c\u5668\u5728\u9a71\u52a8\u529b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8bbe\u8ba1\uff0c\u540c\u65f6\u96c6\u6210\u7684\u5236\u52a8\u529f\u80fd\u4f7f\u5176\u5728\u8f7b\u91cf\u7d27\u51d1\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.08019", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08019", "abs": "https://arxiv.org/abs/2511.08019", "authors": ["Kohei Honda"], "title": "Model Predictive Control via Probabilistic Inference: A Tutorial", "comment": "15 pages, 7 figures", "summary": "Model Predictive Control (MPC) is a fundamental framework for optimizing robot behavior over a finite future horizon. While conventional numerical optimization methods can efficiently handle simple dynamics and cost structures, they often become intractable for the nonlinear or non-differentiable systems commonly encountered in robotics. This article provides a tutorial on probabilistic inference-based MPC, presenting a unified theoretical foundation and a comprehensive overview of representative methods. Probabilistic inference-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have gained significant attention by reinterpreting optimal control as a problem of probabilistic inference. Rather than relying on gradient-based numerical optimization, these methods estimate optimal control distributions through sampling-based techniques, accommodating arbitrary cost functions and dynamics. We first derive the optimal control distribution from the standard optimal control problem, elucidating its probabilistic interpretation and key characteristics. The widely used MPPI algorithm is then derived as a practical example, followed by discussions on prior and variational distribution design, tuning principles, and theoretical aspects. This article aims to serve as a systematic guide for researchers and practitioners seeking to understand, implement, and extend these methods in robotics and beyond.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6982\u7387\u63a8\u7406\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6559\u7a0b\uff0c\u5c06\u6700\u4f18\u63a7\u5236\u91cd\u65b0\u89e3\u91ca\u4e3a\u6982\u7387\u63a8\u7406\u95ee\u9898\uff0c\u4f7f\u7528\u91c7\u6837\u6280\u672f\u4f30\u8ba1\u6700\u4f18\u63a7\u5236\u5206\u5e03\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u6210\u672c\u51fd\u6570\u548c\u52a8\u6001\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u673a\u5668\u4eba\u5b66\u4e2d\u5e38\u89c1\u7684\u975e\u7ebf\u6027\u6216\u4e0d\u53ef\u5fae\u7cfb\u7edf\u65f6\u5f80\u5f80\u96be\u4ee5\u5904\u7406\uff0c\u800c\u57fa\u4e8e\u6982\u7387\u63a8\u7406\u7684MPC\u65b9\u6cd5\u901a\u8fc7\u91c7\u6837\u6280\u672f\u53ef\u4ee5\u5904\u7406\u4efb\u610f\u6210\u672c\u51fd\u6570\u548c\u52a8\u6001\u7cfb\u7edf\u3002", "method": "\u63a8\u5bfc\u6700\u4f18\u63a7\u5236\u5206\u5e03\u7684\u6982\u7387\u89e3\u91ca\uff0c\u4ee5\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u7b97\u6cd5\u4e3a\u4f8b\uff0c\u8ba8\u8bba\u5148\u9a8c\u548c\u53d8\u5206\u5206\u5e03\u8bbe\u8ba1\u3001\u8c03\u4f18\u539f\u5219\u548c\u7406\u8bba\u65b9\u9762\u3002", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8e\u6982\u7387\u63a8\u7406\u7684MPC\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u7684\u5168\u9762\u6982\u8ff0\uff0c\u7279\u522b\u662fMPPI\u7b97\u6cd5\u4f5c\u4e3a\u5b9e\u9645\u5e94\u7528\u793a\u4f8b\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u7cfb\u7edf\u6307\u5357\uff0c\u5e2e\u52a9\u7406\u89e3\u3001\u5b9e\u73b0\u548c\u6269\u5c55\u8fd9\u4e9b\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u5b66\u53ca\u5176\u4ed6\u9886\u57df\u7684\u5e94\u7528\u3002"}}
